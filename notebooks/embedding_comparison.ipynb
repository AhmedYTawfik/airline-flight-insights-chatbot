{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f3c4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Setup\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from statistics import mean, stdev\n",
    "from dotenv import load_dotenv\n",
    "from neo4j import GraphDatabase\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Load environment\n",
    "load_dotenv()\n",
    "\n",
    "NEO4J_URI = os.getenv('NEO4J_URI') or os.getenv('URI')\n",
    "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME') or os.getenv('USERNAME')\n",
    "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD') or os.getenv('PASSWORD')\n",
    "\n",
    "print(f\"Connecting to: {NEO4J_URI}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f75e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "driver.verify_connectivity()\n",
    "print(\"âœ… Connected to Neo4j\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6056db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both embedding models\n",
    "print(\"Loading embedding models...\")\n",
    "\n",
    "start = time.time()\n",
    "model_minilm = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "load_time_minilm = time.time() - start\n",
    "print(f\"  âœ… MiniLM loaded in {load_time_minilm:.2f}s (384 dims)\")\n",
    "\n",
    "start = time.time()\n",
    "model_mpnet = SentenceTransformer('all-mpnet-base-v2')\n",
    "load_time_mpnet = time.time() - start\n",
    "print(f\"  âœ… MPNet loaded in {load_time_mpnet:.2f}s (768 dims)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ab0c78",
   "metadata": {},
   "source": [
    "## 1. Embedding Speed Comparison\n",
    "\n",
    "Compare how fast each model generates embeddings for text of varying lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6937a024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test queries of varying complexity\n",
    "test_queries = [\n",
    "    \"delays at LAX\",\n",
    "    \"What are the top airports with delays?\",\n",
    "    \"How do Millennials travel compared to Baby Boomers in terms of destinations and aircraft preferences?\",\n",
    "    \"Which aircraft type has the best on-time performance and lowest average arrival delays for business class passengers?\",\n",
    "    \"Compare the food satisfaction scores for premier gold loyalty members flying on Boeing 737-800 versus Airbus A320 on routes from Los Angeles to New York with more than 2000 miles traveled.\"\n",
    "]\n",
    "\n",
    "print(\"Embedding Speed Comparison (10 runs each)\\n\" + \"=\"*60)\n",
    "\n",
    "embedding_results = []\n",
    "\n",
    "for query in test_queries:\n",
    "    # MiniLM\n",
    "    minilm_times = []\n",
    "    for _ in range(10):\n",
    "        start = time.time()\n",
    "        _ = model_minilm.encode(query)\n",
    "        minilm_times.append(time.time() - start)\n",
    "    \n",
    "    # MPNet\n",
    "    mpnet_times = []\n",
    "    for _ in range(10):\n",
    "        start = time.time()\n",
    "        _ = model_mpnet.encode(query)\n",
    "        mpnet_times.append(time.time() - start)\n",
    "    \n",
    "    result = {\n",
    "        \"query\": query[:50] + \"...\" if len(query) > 50 else query,\n",
    "        \"query_length\": len(query),\n",
    "        \"minilm_avg_ms\": mean(minilm_times) * 1000,\n",
    "        \"mpnet_avg_ms\": mean(mpnet_times) * 1000,\n",
    "        \"speedup\": mean(mpnet_times) / mean(minilm_times)\n",
    "    }\n",
    "    embedding_results.append(result)\n",
    "    \n",
    "    print(f\"\\nQuery ({len(query)} chars): {query[:50]}...\")\n",
    "    print(f\"  MiniLM: {result['minilm_avg_ms']:.2f}ms\")\n",
    "    print(f\"  MPNet:  {result['mpnet_avg_ms']:.2f}ms\")\n",
    "    print(f\"  â†’ MiniLM is {result['speedup']:.1f}x faster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ee295c",
   "metadata": {},
   "source": [
    "## 2. Retrieval Quality Comparison\n",
    "\n",
    "Compare the top-K results from each model for the same queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7d1cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search_journeys(driver, query_embedding, index_name, top_k=10):\n",
    "    \"\"\"Run vector search on Journey nodes.\"\"\"\n",
    "    search_query = f\"\"\"\n",
    "    CALL db.index.vector.queryNodes('{index_name}', $top_k, $query_embedding)\n",
    "    YIELD node, score\n",
    "    MATCH (p:Passenger)-[:TOOK]->(node)-[:ON]->(f:Flight)\n",
    "    OPTIONAL MATCH (f)-[:DEPARTS_FROM]->(o:Airport)\n",
    "    OPTIONAL MATCH (f)-[:ARRIVES_AT]->(d:Airport)\n",
    "    RETURN node.passenger_class AS passenger_class,\n",
    "           node.arrival_delay_minutes AS delay,\n",
    "           node.actual_flown_miles AS miles,\n",
    "           p.generation AS generation,\n",
    "           p.loyalty_program_level AS loyalty,\n",
    "           f.fleet_type_description AS fleet,\n",
    "           o.station_code AS origin,\n",
    "           d.station_code AS destination,\n",
    "           score\n",
    "    ORDER BY score DESC\n",
    "    LIMIT $top_k\n",
    "    \"\"\"\n",
    "    with driver.session() as session:\n",
    "        result = session.run(search_query, top_k=top_k, query_embedding=query_embedding)\n",
    "        return [dict(r) for r in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204665ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test retrieval with diverse queries\n",
    "retrieval_queries = [\n",
    "    {\n",
    "        \"query\": \"flights with long delays from Los Angeles\",\n",
    "        \"expected_keywords\": [\"LAX\", \"delay\"]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"business class passengers with excellent food service\",\n",
    "        \"expected_keywords\": [\"Business\", \"food\"]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"millennial travelers on long distance routes\",\n",
    "        \"expected_keywords\": [\"Millennial\", \"miles\"]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"premier gold loyalty members with on-time arrivals\",\n",
    "        \"expected_keywords\": [\"premier gold\", \"delay\"]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Boeing 737 aircraft performance\",\n",
    "        \"expected_keywords\": [\"B737\", \"737\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Retrieval Quality Comparison (Top-10 results)\\n\" + \"=\"*60)\n",
    "\n",
    "retrieval_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506f989f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in retrieval_queries:\n",
    "    query = test[\"query\"]\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Generate embeddings\n",
    "    emb_minilm = model_minilm.encode(query).tolist()\n",
    "    emb_mpnet = model_mpnet.encode(query).tolist()\n",
    "    \n",
    "    # Search with MiniLM\n",
    "    start = time.time()\n",
    "    try:\n",
    "        results_minilm = semantic_search_journeys(driver, emb_minilm, \"journey_embedding_minilm\", top_k=10)\n",
    "        search_time_minilm = (time.time() - start) * 1000\n",
    "    except Exception as e:\n",
    "        print(f\"  âš ï¸ MiniLM search failed: {e}\")\n",
    "        results_minilm = []\n",
    "        search_time_minilm = 0\n",
    "    \n",
    "    # Search with MPNet\n",
    "    start = time.time()\n",
    "    try:\n",
    "        results_mpnet = semantic_search_journeys(driver, emb_mpnet, \"journey_embedding_mpnet\", top_k=10)\n",
    "        search_time_mpnet = (time.time() - start) * 1000\n",
    "    except Exception as e:\n",
    "        print(f\"  âš ï¸ MPNet search failed: {e}\")\n",
    "        results_mpnet = []\n",
    "        search_time_mpnet = 0\n",
    "    \n",
    "    # Compare results\n",
    "    print(f\"\\nðŸ“Š MiniLM Results ({len(results_minilm)} found, {search_time_minilm:.1f}ms):\")\n",
    "    for i, r in enumerate(results_minilm[:5], 1):\n",
    "        print(f\"  {i}. score={r['score']:.3f} | {r.get('origin','?')}->{r.get('destination','?')} | {r.get('fleet','?')} | {r.get('generation','?')} | delay={r.get('delay',0)}min\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š MPNet Results ({len(results_mpnet)} found, {search_time_mpnet:.1f}ms):\")\n",
    "    for i, r in enumerate(results_mpnet[:5], 1):\n",
    "        print(f\"  {i}. score={r['score']:.3f} | {r.get('origin','?')}->{r.get('destination','?')} | {r.get('fleet','?')} | {r.get('generation','?')} | delay={r.get('delay',0)}min\")\n",
    "    \n",
    "    # Calculate similarity score statistics\n",
    "    if results_minilm:\n",
    "        minilm_scores = [r['score'] for r in results_minilm]\n",
    "        minilm_avg = mean(minilm_scores)\n",
    "        minilm_max = max(minilm_scores)\n",
    "    else:\n",
    "        minilm_avg = minilm_max = 0\n",
    "        \n",
    "    if results_mpnet:\n",
    "        mpnet_scores = [r['score'] for r in results_mpnet]\n",
    "        mpnet_avg = mean(mpnet_scores)\n",
    "        mpnet_max = max(mpnet_scores)\n",
    "    else:\n",
    "        mpnet_avg = mpnet_max = 0\n",
    "    \n",
    "    retrieval_results.append({\n",
    "        \"query\": query,\n",
    "        \"minilm_search_time_ms\": search_time_minilm,\n",
    "        \"mpnet_search_time_ms\": search_time_mpnet,\n",
    "        \"minilm_avg_score\": minilm_avg,\n",
    "        \"mpnet_avg_score\": mpnet_avg,\n",
    "        \"minilm_max_score\": minilm_max,\n",
    "        \"mpnet_max_score\": mpnet_max,\n",
    "        \"minilm_results_count\": len(results_minilm),\n",
    "        \"mpnet_results_count\": len(results_mpnet)\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ Score Statistics:\")\n",
    "    print(f\"  MiniLM: avg={minilm_avg:.3f}, max={minilm_max:.3f}\")\n",
    "    print(f\"  MPNet:  avg={mpnet_avg:.3f}, max={mpnet_max:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78be863f",
   "metadata": {},
   "source": [
    "## 3. Summary & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efef62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EMBEDDING MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Model loading times\n",
    "print(f\"\\nðŸ“¦ Model Loading Time:\")\n",
    "print(f\"  MiniLM (384 dims): {load_time_minilm:.2f}s\")\n",
    "print(f\"  MPNet  (768 dims): {load_time_mpnet:.2f}s\")\n",
    "\n",
    "# Embedding speed\n",
    "if embedding_results:\n",
    "    avg_minilm = mean([r['minilm_avg_ms'] for r in embedding_results])\n",
    "    avg_mpnet = mean([r['mpnet_avg_ms'] for r in embedding_results])\n",
    "    avg_speedup = mean([r['speedup'] for r in embedding_results])\n",
    "    \n",
    "    print(f\"\\nâš¡ Embedding Speed (avg across queries):\")\n",
    "    print(f\"  MiniLM: {avg_minilm:.2f}ms\")\n",
    "    print(f\"  MPNet:  {avg_mpnet:.2f}ms\")\n",
    "    print(f\"  â†’ MiniLM is {avg_speedup:.1f}x faster\")\n",
    "\n",
    "# Search latency\n",
    "if retrieval_results:\n",
    "    valid_minilm = [r['minilm_search_time_ms'] for r in retrieval_results if r['minilm_search_time_ms'] > 0]\n",
    "    valid_mpnet = [r['mpnet_search_time_ms'] for r in retrieval_results if r['mpnet_search_time_ms'] > 0]\n",
    "    \n",
    "    if valid_minilm and valid_mpnet:\n",
    "        avg_search_minilm = mean(valid_minilm)\n",
    "        avg_search_mpnet = mean(valid_mpnet)\n",
    "        \n",
    "        print(f\"\\nðŸ” Vector Search Latency (Neo4j):\")\n",
    "        print(f\"  MiniLM: {avg_search_minilm:.1f}ms\")\n",
    "        print(f\"  MPNet:  {avg_search_mpnet:.1f}ms\")\n",
    "\n",
    "# Similarity scores\n",
    "if retrieval_results:\n",
    "    valid_minilm_scores = [r['minilm_avg_score'] for r in retrieval_results if r['minilm_avg_score'] > 0]\n",
    "    valid_mpnet_scores = [r['mpnet_avg_score'] for r in retrieval_results if r['mpnet_avg_score'] > 0]\n",
    "    \n",
    "    if valid_minilm_scores and valid_mpnet_scores:\n",
    "        avg_score_minilm = mean(valid_minilm_scores)\n",
    "        avg_score_mpnet = mean(valid_mpnet_scores)\n",
    "        \n",
    "        print(f\"\\nðŸŽ¯ Average Similarity Scores:\")\n",
    "        print(f\"  MiniLM: {avg_score_minilm:.3f}\")\n",
    "        print(f\"  MPNet:  {avg_score_mpnet:.3f}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"RECOMMENDATIONS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "âœ… Use MiniLM (all-MiniLM-L6-v2) when:\n",
    "   - Speed is critical (real-time applications)\n",
    "   - Memory/storage is constrained\n",
    "   - Good-enough quality is acceptable\n",
    "\n",
    "âœ… Use MPNet (all-mpnet-base-v2) when:\n",
    "   - Quality is the top priority\n",
    "   - Latency tolerance is higher\n",
    "   - Complex semantic matching is needed\n",
    "\n",
    "ðŸ’¡ For this Graph-RAG application:\n",
    "   - MiniLM is recommended as default (good balance)\n",
    "   - MPNet available as option for quality-focused queries\n",
    "   - User can switch in UI sidebar based on needs\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f0d3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to JSON\n",
    "comparison_data = {\n",
    "    \"model_info\": {\n",
    "        \"minilm\": {\n",
    "            \"name\": \"all-MiniLM-L6-v2\",\n",
    "            \"dimensions\": 384,\n",
    "            \"load_time_s\": load_time_minilm\n",
    "        },\n",
    "        \"mpnet\": {\n",
    "            \"name\": \"all-mpnet-base-v2\",\n",
    "            \"dimensions\": 768,\n",
    "            \"load_time_s\": load_time_mpnet\n",
    "        }\n",
    "    },\n",
    "    \"embedding_speed_results\": embedding_results,\n",
    "    \"retrieval_results\": retrieval_results\n",
    "}\n",
    "\n",
    "with open('embedding_comparison_results.json', 'w') as f:\n",
    "    json.dump(comparison_data, f, indent=2)\n",
    "\n",
    "print(\"âœ… Results saved to embedding_comparison_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2184a6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON TABLE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Metric':<35} {'MiniLM (384d)':<20} {'MPNet (768d)':<20}\")\n",
    "print(\"-\"*80)\n",
    "print(f\"{'Model Load Time':<35} {f'{load_time_minilm:.2f}s':<20} {f'{load_time_mpnet:.2f}s':<20}\")\n",
    "\n",
    "if embedding_results:\n",
    "    print(f\"{'Avg Embedding Time':<35} {f'{avg_minilm:.2f}ms':<20} {f'{avg_mpnet:.2f}ms':<20}\")\n",
    "\n",
    "if retrieval_results and valid_minilm and valid_mpnet:\n",
    "    print(f\"{'Avg Search Latency':<35} {f'{avg_search_minilm:.1f}ms':<20} {f'{avg_search_mpnet:.1f}ms':<20}\")\n",
    "\n",
    "if retrieval_results and valid_minilm_scores and valid_mpnet_scores:\n",
    "    print(f\"{'Avg Similarity Score':<35} {f'{avg_score_minilm:.3f}':<20} {f'{avg_score_mpnet:.3f}':<20}\")\n",
    "\n",
    "print(f\"{'Vector Dimensions':<35} {'384':<20} {'768':<20}\")\n",
    "print(f\"{'Index Size (relative)':<35} {'1x (smaller)':<20} {'2x (larger)':<20}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71721f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close connection\n",
    "driver.close()\n",
    "print(\"\\nâœ… Neo4j connection closed\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
