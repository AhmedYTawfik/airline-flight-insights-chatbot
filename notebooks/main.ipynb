{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# Airline Flight Insights - Full Pipeline\n",
                "\n",
                "This notebook provides a complete Graph-RAG pipeline including:\n",
                "1. **Neo4j Database Connection**\n",
                "2. **LLM Setup** (Gemini)\n",
                "3. **Embeddings** - Vector embeddings for semantic search\n",
                "4. **Hybrid Retrieval** - Cypher + Semantic search\n",
                "5. **Question Answering**"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "section-1",
            "metadata": {},
            "source": [
                "## 1. Imports and Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "from neo4j import GraphDatabase, Driver\n",
                "from dotenv import load_dotenv, find_dotenv\n",
                "from langchain_groq import ChatGroq\n",
                "from sentence_transformers import SentenceTransformer\n",
                "from typing import List, Dict, Any, Optional, Callable, Tuple\n",
                "import numpy as np\n",
                "import os\n",
                "import json\n",
                "import re"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "env-loader",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load environment variables\n",
                "load_dotenv(find_dotenv())\n",
                "\n",
                "NEO4J_URI = os.getenv('NEO4J_URI') or os.getenv('URI')\n",
                "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME') or os.getenv('USERNAME')\n",
                "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD') or os.getenv('PASSWORD')\n",
                "groq_api_key = os.getenv('GROQ_API_KEY') or os.getenv('GROQ')\n",
                "\n",
                "print(f\"URI: {NEO4J_URI}\")\n",
                "print(f\"Groq API key loaded: {'Yes' if groq_api_key else 'No'}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 127,
            "id": "driver-setup",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Connected to Neo4j!\n"
                    ]
                }
            ],
            "source": [
                "# Create Neo4j driver\n",
                "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
                "driver.verify_connectivity()\n",
                "print(\"Connected to Neo4j!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "llm-setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Groq: FREE, 30+ requests/minute, very fast!\n",
                "llm = ChatGroq(\n",
                "    model=\"llama-3.3-70b-versatile\",\n",
                "    api_key=groq_api_key,\n",
                "    temperature=0\n",
                ")\n",
                "print(\"Groq LLM loaded! (llama-3.3-70b-versatile)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "section-2",
            "metadata": {},
            "source": [
                "## 2. Cypher Queries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 129,
            "id": "queries-list",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded 20 queries\n"
                    ]
                }
            ],
            "source": [
                "queries = [\n",
                "    # Intent 1: Operational Delay Diagnostics\n",
                "    \"MATCH (j:Journey)-[:ON]->(f:Flight)-[:ARRIVES_AT]->(a:Airport) RETURN a.station_code AS destination, SUM(j.arrival_delay_minutes) AS total_delay ORDER BY total_delay DESC LIMIT $x\",\n",
                "    \"MATCH (j:Journey)-[:ON]->(f:Flight)-[:ARRIVES_AT]->(a:Airport) RETURN a.station_code AS destination, SUM(j.arrival_delay_minutes) AS total_delay ORDER BY total_delay ASC LIMIT $x\",\n",
                "    \"MATCH (j:Journey)-[:ON]->(f:Flight)-[:DEPARTS_FROM]->(a:Airport) RETURN a.station_code AS origin, SUM(j.arrival_delay_minutes) AS total_delay ORDER BY total_delay DESC LIMIT $x\",\n",
                "    \"MATCH (j:Journey)-[:ON]->(f:Flight)-[:DEPARTS_FROM]->(a:Airport) RETURN a.station_code AS origin, SUM(j.arrival_delay_minutes) AS total_delay ORDER BY total_delay ASC LIMIT $x\",\n",
                "    \"MATCH (o:Airport {station_code: $origin_station_code})<-[:DEPARTS_FROM]-(f:Flight)-[:ARRIVES_AT]->(d:Airport), (j:Journey)-[:ON]->(f) WITH o, d, AVG(j.arrival_delay_minutes) AS avg_delay WHERE avg_delay > $x RETURN o.station_code AS origin, d.station_code AS destination, avg_delay\",\n",
                "    \"MATCH (j:Journey {number_of_legs: $x}) RETURN AVG(j.arrival_delay_minutes) AS avg_delay\",\n",
                "    # Intent 2: Service Quality\n",
                "    \"MATCH (o:Airport)<-[:DEPARTS_FROM]-(f:Flight)-[:ARRIVES_AT]->(d:Airport), (j:Journey {passenger_class: $class_name})-[:ON]->(f) WITH o, d, AVG(j.food_satisfaction_score) AS avg_food_score WHERE avg_food_score < $threshold RETURN o.station_code AS origin, d.station_code AS destination, avg_food_score\",\n",
                "    \"MATCH (j:Journey {food_satisfaction_score: 1})-[:ON]->(f:Flight) WHERE j.actual_flown_miles > $x RETURN DISTINCT f.flight_number\",\n",
                "    # Intent 3: Fleet Performance\n",
                "    \"MATCH (j:Journey)-[:ON]->(f:Flight) WHERE j.arrival_delay_minutes > $x RETURN f.fleet_type_description AS aircraft_type, COUNT(j) AS delay_frequency ORDER BY delay_frequency DESC LIMIT 1\",\n",
                "    \"MATCH (j:Journey)-[:ON]->(f:Flight {fleet_type_description: $x}) RETURN AVG(j.food_satisfaction_score) AS avg_food_score\",\n",
                "    \"MATCH (j:Journey)-[:ON]->(f:Flight {fleet_type_description: $x}) RETURN AVG(j.actual_flown_miles) AS avg_miles\",\n",
                "    \"MATCH (j:Journey)-[:ON]->(f:Flight {fleet_type_description: $x}) WITH COUNT(j) AS total_flights, COUNT(CASE WHEN j.arrival_delay_minutes < 0 THEN 1 END) AS early_flights RETURN (TOFLOAT(early_flights) / total_flights) * 100 AS early_arrival_percentage\",\n",
                "    # Intent 3b: Aircraft Performance Aggregation (NEW)\n",
                "    \"MATCH (j:Journey)-[:ON]->(f:Flight) RETURN f.fleet_type_description AS aircraft_type, AVG(j.arrival_delay_minutes) AS avg_delay, COUNT(j) AS flight_count ORDER BY avg_delay ASC LIMIT $x\",\n",
                "    \"MATCH (j:Journey)-[:ON]->(f:Flight) RETURN f.fleet_type_description AS aircraft_type, AVG(j.arrival_delay_minutes) AS avg_delay, COUNT(j) AS flight_count ORDER BY avg_delay DESC LIMIT $x\",\n",
                "    \"MATCH (j:Journey)-[:ON]->(f:Flight) WITH f.fleet_type_description AS aircraft_type, COUNT(j) AS total, COUNT(CASE WHEN j.arrival_delay_minutes <= 0 THEN 1 END) AS on_time RETURN aircraft_type, (toFloat(on_time) / total) * 100 AS on_time_pct, total AS flight_count ORDER BY on_time_pct DESC LIMIT $x\",\n",
                "    # Intent 4: Loyalty\n",
                "    \"MATCH (p:Passenger {loyalty_program_level: $loyalty_program_level})-[:TOOK]->(j:Journey) RETURN AVG(j.arrival_delay_minutes) AS avg_delay\",\n",
                "    \"MATCH (p:Passenger {loyalty_program_level: $loyalty_program_level})-[:TOOK]->(j:Journey) WHERE j.arrival_delay_minutes > $x RETURN p.record_locator AS passenger_id, j.arrival_delay_minutes AS delay\",\n",
                "    # Intent 5: Demographics\n",
                "    \"MATCH (p:Passenger {generation: $generation})-[:TOOK]->(j:Journey)-[:ON]->(f:Flight) WHERE j.actual_flown_miles > $threshold RETURN f.fleet_type_description AS aircraft_type, COUNT(f) AS usage_count ORDER BY usage_count DESC LIMIT 1\",\n",
                "    \"MATCH (p:Passenger {generation: $generation})-[:TOOK]->(j:Journey)-[:ON]->(f:Flight) RETURN f.fleet_type_description AS fleet_type, COUNT(f) AS usage_count ORDER BY usage_count DESC LIMIT 1\",\n",
                "    \"MATCH (p:Passenger {generation: $generation})-[:TOOK]->(j:Journey)-[:ON]->(f:Flight)-[:ARRIVES_AT]->(a:Airport) RETURN a.station_code AS destination, COUNT(p) AS passenger_volume ORDER BY passenger_volume DESC LIMIT $x\"\n",
                "]\n",
                "\n",
                "query_descriptions = [\n",
                "    \"Identify the top ${x} destination stations with the highest accumulated arrival delay minutes.\",\n",
                "    \"Identify the top ${x} destination stations with the lowest accumulated arrival delay minutes.\",\n",
                "    \"Identify the top ${x} origin stations with the highest accumulated arrival delay minutes.\",\n",
                "    \"Identify the top ${x} origin stations with the lowest accumulated arrival delay minutes.\",\n",
                "    \"Find routes from the origin station ${origin_station_code} where the average arrival delay exceeds ${x} minutes.\",\n",
                "    \"Calculate the average arrival delay for flights consisting of exactly ${x} legs.\",\n",
                "    \"Identify routes for the passenger class ${class_name} where the average food satisfaction score is below ${threshold}.\",\n",
                "    \"List the flight numbers for journeys longer than ${x} miles where the food satisfaction score was 1.\",\n",
                "    \"Identify the aircraft type that has the highest frequency of arrival delays greater than ${x} minutes.\",\n",
                "    \"Calculate the average food satisfaction score for passengers flying on the ${x} fleet.\",\n",
                "    \"Calculate the average actual flown miles for the ${x} fleet.\",\n",
                "    \"Calculate the percentage of early arrivals for the ${x} fleet.\",\n",
                "    # NEW: Aircraft performance aggregation\n",
                "    \"List the top ${x} aircraft types with the LOWEST average arrival delay (best on-time performance).\",\n",
                "    \"List the top ${x} aircraft types with the HIGHEST average arrival delay (worst on-time performance).\",\n",
                "    \"List the top ${x} aircraft types by on-time arrival percentage (arrivals with delay <= 0 minutes).\",\n",
                "    # Loyalty\n",
                "    \"Calculate the average arrival delay experienced by passengers with the loyalty level ${loyalty_program_level}.\",\n",
                "    \"Find the record locators for passengers with loyalty level ${loyalty_program_level} who experienced a delay greater than ${x} minutes.\",\n",
                "    # Demographics\n",
                "    \"Identify the most common aircraft type used by the ${generation} generation for journeys exceeding ${threshold} miles.\",\n",
                "    \"Identify the most frequently used fleet type for the ${generation} generation.\",\n",
                "    \"Identify the top ${x} destination stations for the ${generation} generation based on passenger volume.\"\n",
                "]\n",
                "\n",
                "print(f\"Loaded {len(queries)} queries\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "section-3",
            "metadata": {},
            "source": [
                "## 3. Query Execution Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 130,
            "id": "run-query",
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_query(query_index: int, **params) -> list:\n",
                "    \"\"\"Run a query by index with parameters.\"\"\"\n",
                "    if query_index < 0 or query_index >= len(queries):\n",
                "        raise ValueError(f\"Query index {query_index} out of range (0-{len(queries)-1})\")\n",
                "    with driver.session() as session:\n",
                "        result = session.run(queries[query_index], **params)\n",
                "        return [record.data() for record in result]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 131,
            "id": "kg-schema",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded KG schema:\n",
                        "  - 158 airport codes\n",
                        "  - Generations: ['Boomer', 'Gen X', 'Gen Z', 'Millennial', 'NBK', 'Silent']\n",
                        "  - Loyalty levels: ['NBK', 'global services', 'non-elite', 'premier 1k', 'premier gold', 'premier platinum', 'premier silver']\n",
                        "  - Fleet types: 20 types\n",
                        "  - Passenger classes: ['Economy']\n"
                    ]
                }
            ],
            "source": [
                "# Load KG schema values for better parameter matching\n",
                "def load_kg_schema(driver) -> Dict[str, Any]:\n",
                "    \"\"\"Query the KG to get valid values for each parameter field.\"\"\"\n",
                "    schema = {}\n",
                "    \n",
                "    with driver.session() as session:\n",
                "        # Airport codes\n",
                "        result = session.run('MATCH (a:Airport) RETURN DISTINCT a.station_code AS code ORDER BY code')\n",
                "        schema['airport_codes'] = [r['code'] for r in result]\n",
                "        \n",
                "        # Passenger classes\n",
                "        result = session.run('MATCH (j:Journey) RETURN DISTINCT j.passenger_class AS class ORDER BY class')\n",
                "        schema['passenger_classes'] = [r['class'] for r in result if r['class']]\n",
                "        \n",
                "        # Generations\n",
                "        result = session.run('MATCH (p:Passenger) RETURN DISTINCT p.generation AS gen ORDER BY gen')\n",
                "        schema['generations'] = [r['gen'] for r in result if r['gen']]\n",
                "        \n",
                "        # Loyalty levels\n",
                "        result = session.run('MATCH (p:Passenger) RETURN DISTINCT p.loyalty_program_level AS level ORDER BY level')\n",
                "        schema['loyalty_levels'] = [r['level'] for r in result if r['level']]\n",
                "        \n",
                "        # Fleet types\n",
                "        result = session.run('MATCH (f:Flight) RETURN DISTINCT f.fleet_type_description AS fleet ORDER BY fleet')\n",
                "        schema['fleet_types'] = [r['fleet'] for r in result if r['fleet']]\n",
                "        \n",
                "        # Number of legs\n",
                "        result = session.run('MATCH (j:Journey) RETURN DISTINCT j.number_of_legs AS legs ORDER BY legs')\n",
                "        schema['number_of_legs'] = [r['legs'] for r in result if r['legs']]\n",
                "    \n",
                "    return schema\n",
                "\n",
                "# Load schema on startup\n",
                "kg_schema = load_kg_schema(driver)\n",
                "print(f\"Loaded KG schema:\")\n",
                "print(f\"  - {len(kg_schema['airport_codes'])} airport codes\")\n",
                "print(f\"  - Generations: {kg_schema['generations']}\")\n",
                "print(f\"  - Loyalty levels: {kg_schema['loyalty_levels']}\")\n",
                "print(f\"  - Fleet types: {len(kg_schema['fleet_types'])} types\")\n",
                "print(f\"  - Passenger classes: {kg_schema['passenger_classes']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 132,
            "id": "get-context",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_context(prompt: str) -> list:\n",
                "    \"\"\"Use Groq LLM to identify relevant queries and extract parameters with KG schema awareness.\"\"\"\n",
                "    safe_descriptions = [desc.replace('${', '<').replace('}', '>') for desc in query_descriptions]\n",
                "    query_list = \"\\n\".join([f\"{i}: {desc}\" for i, desc in enumerate(safe_descriptions)])\n",
                "    \n",
                "    # Build schema reference for the LLM\n",
                "    schema_info = (\n",
                "        \"VALID VALUES FROM THE DATABASE:\\n\"\n",
                "        f\"- origin_station_code/destination: {kg_schema['airport_codes'][:20]}... ({len(kg_schema['airport_codes'])} total)\\n\"\n",
                "        f\"- generation: {kg_schema['generations']}\\n\"\n",
                "        f\"- loyalty_program_level: {kg_schema['loyalty_levels']}\\n\"\n",
                "        f\"- class_name: {kg_schema['passenger_classes']}\\n\"\n",
                "        f\"- fleet types (for x when fleet-related): {kg_schema['fleet_types']}\\n\"\n",
                "        f\"- number_of_legs: {kg_schema['number_of_legs']}\\n\"\n",
                "    )\n",
                "    \n",
                "    full_prompt = (\n",
                "        \"You are an expert at analyzing user questions about airline flight data.\\n\\n\"\n",
                "        \"Available queries:\\n\" + query_list + \"\\n\\n\"\n",
                "        + schema_info + \"\\n\"\n",
                "        \"PARAMETER RULES:\\n\"\n",
                "        \"- x: a number for counts/limits (default 5), delay thresholds (default 30), or miles threshold\\n\"\n",
                "        \"- For fleet queries (indices 9-11), x must be an EXACT fleet type from the list above\\n\"\n",
                "        \"- Match user terms to closest valid values (e.g., 'Baby Boomer' -> 'Boomer', 'gold member' -> 'premier gold')\\n\"\n",
                "        \"- Use exact values from the database schema above\\n\\n\"\n",
                "        'CRITICAL: Return ONLY ONE valid JSON array on a single line. No explanations.\\n'\n",
                "        'Format: [{\"query_index\": 0, \"params\": {\"x\": 5}}]\\n\\n'\n",
                "        \"User question: \" + prompt + \"\\n\\nJSON:\"\n",
                "    )\n",
                "    \n",
                "    response = llm.invoke(full_prompt)\n",
                "    response_text = response.content.strip()\n",
                "    \n",
                "    # Clean up response - remove markdown and extra whitespace\n",
                "    response_text = response_text.replace('```json', '').replace('```', '').strip()\n",
                "    \n",
                "    # Find the FIRST valid JSON array (ignore any additional lines)\n",
                "    # Look for the first line that starts with '['\n",
                "    for line in response_text.split('\\n'):\n",
                "        line = line.strip()\n",
                "        if line.startswith('[') and line.endswith(']'):\n",
                "            try:\n",
                "                return json.loads(line)\n",
                "            except json.JSONDecodeError:\n",
                "                continue\n",
                "    \n",
                "    # Fallback: try to find any JSON array in the response\n",
                "    json_match = re.search(r'\\[\\s*\\{[^\\[]*\\}\\s*\\]', response_text, re.DOTALL)\n",
                "    if json_match:\n",
                "        try:\n",
                "            return json.loads(json_match.group())\n",
                "        except json.JSONDecodeError as e:\n",
                "            print(f\"JSON parse error: {e}\")\n",
                "            print(f\"Response was: {response_text[:200]}\")\n",
                "    \n",
                "    return []"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 133,
            "id": "format-result",
            "metadata": {},
            "outputs": [],
            "source": [
                "def format_query_result(query_index: int, **params) -> str:\n",
                "    \"\"\"Run query and format result as context.\"\"\"\n",
                "    if query_index < 0 or query_index >= len(queries):\n",
                "        return f\"Error: Query index {query_index} out of range.\"\n",
                "    \n",
                "    description = query_descriptions[query_index]\n",
                "    for name, value in params.items():\n",
                "        description = description.replace(f\"${{{name}}}\", str(value))\n",
                "    \n",
                "    try:\n",
                "        results = run_query(query_index, **params)\n",
                "    except Exception as e:\n",
                "        return f'Error for \"{description}\": {e}'\n",
                "    \n",
                "    if not results:\n",
                "        return f'\"{description}\": No data found.'\n",
                "    \n",
                "    formatted = []\n",
                "    for r in results:\n",
                "        parts = [f\"{k}: {v:.2f}\" if isinstance(v, float) else f\"{k}: {v}\" for k, v in r.items()]\n",
                "        formatted.append(\"  - \" + \", \".join(parts))\n",
                "    \n",
                "    return f'\"{description}\":\\n' + \"\\n\".join(formatted)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "section-4",
            "metadata": {},
            "source": [
                "## 4. Embeddings Module\n",
                "\n",
                "Vector embeddings for semantic search. Models:\n",
                "- `minilm`: all-MiniLM-L6-v2 (384 dims, fast)\n",
                "- `mpnet`: all-mpnet-base-v2 (768 dims, higher quality)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 134,
            "id": "embedding-config",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Embedding model configurations\n",
                "EMBEDDING_MODELS = {\n",
                "    \"minilm\": {\"name\": \"all-MiniLM-L6-v2\", \"dimensions\": 384, \"property_name\": \"embedding_minilm\"},\n",
                "    \"mpnet\": {\"name\": \"all-mpnet-base-v2\", \"dimensions\": 768, \"property_name\": \"embedding_mpnet\"}\n",
                "}\n",
                "\n",
                "_model_cache: Dict[str, SentenceTransformer] = {}\n",
                "\n",
                "def get_model(model_key: str) -> SentenceTransformer:\n",
                "    \"\"\"Load and cache an embedding model.\"\"\"\n",
                "    if model_key not in EMBEDDING_MODELS:\n",
                "        raise ValueError(f\"Unknown model: {model_key}. Use 'minilm' or 'mpnet'\")\n",
                "    if model_key not in _model_cache:\n",
                "        print(f\"Loading {EMBEDDING_MODELS[model_key]['name']}...\")\n",
                "        _model_cache[model_key] = SentenceTransformer(EMBEDDING_MODELS[model_key][\"name\"])\n",
                "        print(\"Model loaded!\")\n",
                "    return _model_cache[model_key]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "text-representations",
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_journey_sentences(props: Dict[str, Any]) -> List[str]:\n",
                "    \"\"\"Create MULTIPLE focused sentences for a Journey (better for retrieval).\"\"\"\n",
                "    sentences = []\n",
                "    \n",
                "    # Sentence 1: Route & Flight info\n",
                "    flight_number = props.get('flight_number', '')\n",
                "    fleet_type = props.get('fleet_type', '')\n",
                "    origin = props.get('origin', '')\n",
                "    destination = props.get('destination', '')\n",
                "    if flight_number and origin and destination:\n",
                "        route_text = f\"Flight {flight_number} from {origin} to {destination}\"\n",
                "        if fleet_type:\n",
                "            route_text += f\" operated by {fleet_type} aircraft\"\n",
                "        sentences.append(route_text + \".\")\n",
                "    \n",
                "    # Sentence 2: Passenger demographics & loyalty\n",
                "    generation = props.get('generation', '')\n",
                "    loyalty = props.get('loyalty_program_level', '')\n",
                "    if generation or loyalty:\n",
                "        passenger_text = f\"Passenger is a {generation}\" if generation else \"Passenger\"\n",
                "        if loyalty:\n",
                "            passenger_text += f\" with {loyalty} loyalty program level\"\n",
                "        sentences.append(passenger_text + \".\")\n",
                "    \n",
                "    # Sentence 3: Journey experience\n",
                "    passenger_class = props.get('passenger_class', 'Economy')\n",
                "    miles = props.get('actual_flown_miles', 0)\n",
                "    delay = props.get('arrival_delay_minutes', 0)\n",
                "    legs = props.get('number_of_legs', 1)\n",
                "    food_score = props.get('food_satisfaction_score', 3)\n",
                "    \n",
                "    delay_text = f\"arrived {abs(delay)} minutes early\" if delay < 0 else \"on time\" if delay == 0 else f\"delayed {delay} minutes\"\n",
                "    food_labels = {1: \"very poor\", 2: \"poor\", 3: \"average\", 4: \"good\", 5: \"excellent\"}\n",
                "    satisfaction = food_labels.get(food_score, \"average\")\n",
                "    \n",
                "    exp_text = f\"{passenger_class} class journey covering {miles:.0f} miles over {legs} segment{'s' if legs > 1 else ''}, {delay_text}, {satisfaction} food satisfaction.\"\n",
                "    sentences.append(exp_text)\n",
                "    \n",
                "    return sentences\n",
                "\n",
                "\n",
                "def create_journey_text(props: Dict[str, Any]) -> str:\n",
                "    \"\"\"Create combined text from all journey sentences.\"\"\"\n",
                "    return \" \".join(create_journey_sentences(props))\n",
                "\n",
                "\n",
                "def create_flight_text(props: Dict[str, Any], origin: str = None, destination: str = None) -> str:\n",
                "    \"\"\"Create text representation of a Flight node.\"\"\"\n",
                "    flight_num = props.get('flight_number', 'Unknown')\n",
                "    fleet = props.get('fleet_type_description', 'Unknown aircraft')\n",
                "    route = f\" from {origin} to {destination}\" if origin and destination else \"\"\n",
                "    return f\"Flight {flight_num} operated by {fleet}{route}.\"\n",
                "\n",
                "\n",
                "def create_passenger_text(props: Dict[str, Any]) -> str:\n",
                "    \"\"\"Create text representation of a Passenger node.\"\"\"\n",
                "    return f\"A {props.get('generation', 'unknown')} passenger with {props.get('loyalty_program_level', 'unknown')} loyalty status.\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 136,
            "id": "embedding-generation",
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_embeddings(texts: List[str], model_key: str = \"minilm\") -> np.ndarray:\n",
                "    \"\"\"Generate embeddings for a list of texts.\"\"\"\n",
                "    model = get_model(model_key)\n",
                "    return model.encode(texts, show_progress_bar=True, convert_to_numpy=True)\n",
                "\n",
                "\n",
                "def generate_single_embedding(text: str, model_key: str = \"minilm\") -> List[float]:\n",
                "    \"\"\"Generate embedding for a single text.\"\"\"\n",
                "    model = get_model(model_key)\n",
                "    return model.encode(text, convert_to_numpy=True).tolist()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 137,
            "id": "neo4j-fetch",
            "metadata": {},
            "outputs": [],
            "source": [
                "def fetch_journey_nodes(driver: Driver) -> List[Dict[str, Any]]:\n",
                "    \"\"\"Fetch Journey nodes with ENRICHED data including passenger and flight info.\"\"\"\n",
                "    query = \"\"\"\n",
                "    MATCH (p:Passenger)-[:TOOK]->(j:Journey)-[:ON]->(f:Flight)\n",
                "    OPTIONAL MATCH (f)-[:DEPARTS_FROM]->(o:Airport)\n",
                "    OPTIONAL MATCH (f)-[:ARRIVES_AT]->(d:Airport)\n",
                "    RETURN j.feedback_ID AS feedback_ID,\n",
                "           j.passenger_class AS passenger_class,\n",
                "           j.food_satisfaction_score AS food_satisfaction_score,\n",
                "           j.arrival_delay_minutes AS arrival_delay_minutes,\n",
                "           j.actual_flown_miles AS actual_flown_miles,\n",
                "           j.number_of_legs AS number_of_legs,\n",
                "           p.generation AS generation,\n",
                "           p.loyalty_program_level AS loyalty_program_level,\n",
                "           f.flight_number AS flight_number,\n",
                "           f.fleet_type_description AS fleet_type,\n",
                "           o.station_code AS origin,\n",
                "           d.station_code AS destination\n",
                "    \"\"\"\n",
                "    with driver.session() as session:\n",
                "        result = session.run(query)\n",
                "        return [{\"feedback_ID\": r[\"feedback_ID\"], \"properties\": dict(r)} for r in result]\n",
                "\n",
                "\n",
                "def fetch_flight_nodes(driver: Driver) -> List[Dict[str, Any]]:\n",
                "    \"\"\"Fetch all Flight nodes from Neo4j with route info.\"\"\"\n",
                "    query = \"\"\"\n",
                "    MATCH (f:Flight)\n",
                "    OPTIONAL MATCH (f)-[:DEPARTS_FROM]->(origin:Airport)\n",
                "    OPTIONAL MATCH (f)-[:ARRIVES_AT]->(dest:Airport)\n",
                "    RETURN f.flight_number AS flight_number, f.fleet_type_description AS fleet_type_description,\n",
                "           origin.station_code AS origin, dest.station_code AS destination\n",
                "    \"\"\"\n",
                "    with driver.session() as session:\n",
                "        result = session.run(query)\n",
                "        return [{\n",
                "            \"flight_number\": r[\"flight_number\"],\n",
                "            \"fleet_type_description\": r[\"fleet_type_description\"],\n",
                "            \"properties\": {\"flight_number\": r[\"flight_number\"], \"fleet_type_description\": r[\"fleet_type_description\"]},\n",
                "            \"origin\": r[\"origin\"], \"destination\": r[\"destination\"]\n",
                "        } for r in result]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 138,
            "id": "vector-index",
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_vector_index(driver: Driver, model_key: str, node_label: str = \"Journey\"):\n",
                "    \"\"\"Create a vector index in Neo4j.\"\"\"\n",
                "    config = EMBEDDING_MODELS[model_key]\n",
                "    index_name = f\"{node_label.lower()}_{config['property_name']}\"\n",
                "    \n",
                "    create_query = f\"\"\"\n",
                "    CREATE VECTOR INDEX {index_name} IF NOT EXISTS\n",
                "    FOR (n:{node_label}) ON n.{config['property_name']}\n",
                "    OPTIONS {{indexConfig: {{\n",
                "        `vector.dimensions`: {config['dimensions']},\n",
                "        `vector.similarity_function`: 'cosine'\n",
                "    }}}}\n",
                "    \"\"\"\n",
                "    with driver.session() as session:\n",
                "        try:\n",
                "            session.run(f\"DROP INDEX {index_name} IF EXISTS\")\n",
                "        except: pass\n",
                "        session.run(create_query)\n",
                "        print(f\"Created index: {index_name}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "store-embeddings",
            "metadata": {},
            "outputs": [],
            "source": [
                "def store_journey_embeddings(driver: Driver, feedback_ids: List[str], embeddings: np.ndarray, \n",
                "                              model_key: str = \"minilm\", batch_size: int = 100):\n",
                "    \"\"\"Store embeddings for Journey nodes.\"\"\"\n",
                "    prop = EMBEDDING_MODELS[model_key][\"property_name\"]\n",
                "    query = f\"UNWIND $batch AS item MATCH (j:Journey {{feedback_ID: item.feedback_ID}}) SET j.{prop} = item.embedding\"\n",
                "    \n",
                "    with driver.session() as session:\n",
                "        for i in range(0, len(feedback_ids), batch_size):\n",
                "            batch = [{\"feedback_ID\": feedback_ids[j], \"embedding\": embeddings[j].tolist()} \n",
                "                     for j in range(i, min(i + batch_size, len(feedback_ids)))]\n",
                "            session.run(query, batch=batch)\n",
                "            print(f\"Stored {min(i + batch_size, len(feedback_ids))}/{len(feedback_ids)}...\")\n",
                "\n",
                "\n",
                "def store_journey_multi_embeddings(driver: Driver, journeys: List[Dict], all_embeddings: Dict[str, np.ndarray],\n",
                "                                    model_key: str = \"minilm\", batch_size: int = 100):\n",
                "    \"\"\"Store multiple embeddings per Journey (route, passenger, experience).\"\"\"\n",
                "    base_prop = EMBEDDING_MODELS[model_key][\"property_name\"]\n",
                "    \n",
                "    for emb_type in ['route', 'passenger', 'experience']:\n",
                "        if emb_type not in all_embeddings:\n",
                "            continue\n",
                "        prop = f\"{base_prop}_{emb_type}\"\n",
                "        query = f\"UNWIND $batch AS item MATCH (j:Journey {{feedback_ID: item.feedback_ID}}) SET j.{prop} = item.embedding\"\n",
                "        embeddings = all_embeddings[emb_type]\n",
                "        \n",
                "        with driver.session() as session:\n",
                "            for i in range(0, len(journeys), batch_size):\n",
                "                batch = [{\"feedback_ID\": journeys[j][\"feedback_ID\"], \"embedding\": embeddings[j].tolist()} \n",
                "                         for j in range(i, min(i + batch_size, len(journeys)))]\n",
                "                session.run(query, batch=batch)\n",
                "        print(f\"Stored {emb_type} embeddings\")\n",
                "\n",
                "\n",
                "def store_flight_embeddings(driver: Driver, flights: List[Dict], embeddings: np.ndarray,\n",
                "                            model_key: str = \"minilm\", batch_size: int = 100):\n",
                "    \"\"\"Store embeddings for Flight nodes.\"\"\"\n",
                "    prop = EMBEDDING_MODELS[model_key][\"property_name\"]\n",
                "    query = f\"UNWIND $batch AS item MATCH (f:Flight {{flight_number: item.flight_number, fleet_type_description: item.fleet_type_description}}) SET f.{prop} = item.embedding\"\n",
                "    \n",
                "    with driver.session() as session:\n",
                "        for i in range(0, len(flights), batch_size):\n",
                "            batch = [{\"flight_number\": flights[j][\"flight_number\"], \n",
                "                      \"fleet_type_description\": flights[j][\"fleet_type_description\"],\n",
                "                      \"embedding\": embeddings[j].tolist()} \n",
                "                     for j in range(i, min(i + batch_size, len(flights)))]\n",
                "            session.run(query, batch=batch)\n",
                "            print(f\"Stored {min(i + batch_size, len(flights))}/{len(flights)}...\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 140,
            "id": "semantic-search",
            "metadata": {},
            "outputs": [],
            "source": [
                "def semantic_search_journeys(driver: Driver, query_text: str, model_key: str = \"minilm\", top_k: int = 5) -> List[Dict]:\n",
                "    \"\"\"Semantic search on Journey nodes - returns enriched data.\"\"\"\n",
                "    query_embedding = generate_single_embedding(query_text, model_key)\n",
                "    index_name = f\"journey_{EMBEDDING_MODELS[model_key]['property_name']}\"\n",
                "    \n",
                "    # Updated query to fetch connected entities\n",
                "    search_query = f\"\"\"\n",
                "    CALL db.index.vector.queryNodes('{index_name}', $top_k, $query_embedding)\n",
                "    YIELD node, score\n",
                "    MATCH (p:Passenger)-[:TOOK]->(node)-[:ON]->(f:Flight)\n",
                "    OPTIONAL MATCH (f)-[:DEPARTS_FROM]->(o:Airport)\n",
                "    OPTIONAL MATCH (f)-[:ARRIVES_AT]->(d:Airport)\n",
                "    RETURN node.feedback_ID AS feedback_ID, \n",
                "           node.passenger_class AS passenger_class,\n",
                "           node.food_satisfaction_score AS food_satisfaction_score,\n",
                "           node.arrival_delay_minutes AS arrival_delay_minutes,\n",
                "           node.actual_flown_miles AS actual_flown_miles,\n",
                "           node.number_of_legs AS number_of_legs,\n",
                "           p.generation AS generation,\n",
                "           p.loyalty_program_level AS loyalty_program_level,\n",
                "           f.flight_number AS flight_number,\n",
                "           f.fleet_type_description AS fleet_type,\n",
                "           o.station_code AS origin,\n",
                "           d.station_code AS destination,\n",
                "           score\n",
                "    ORDER BY score DESC\n",
                "    \"\"\"\n",
                "    with driver.session() as session:\n",
                "        result = session.run(search_query, top_k=top_k, query_embedding=query_embedding)\n",
                "        return [{**dict(r), \"similarity_score\": r[\"score\"]} for r in result]\n",
                "\n",
                "\n",
                "def semantic_search_flights(driver: Driver, query_text: str, model_key: str = \"minilm\", top_k: int = 5) -> List[Dict]:\n",
                "    \"\"\"Semantic search on Flight nodes.\"\"\"\n",
                "    query_embedding = generate_single_embedding(query_text, model_key)\n",
                "    index_name = f\"flight_{EMBEDDING_MODELS[model_key]['property_name']}\"\n",
                "    \n",
                "    search_query = f\"\"\"\n",
                "    CALL db.index.vector.queryNodes('{index_name}', $top_k, $query_embedding)\n",
                "    YIELD node, score\n",
                "    MATCH (node)-[:DEPARTS_FROM]->(origin:Airport)\n",
                "    MATCH (node)-[:ARRIVES_AT]->(dest:Airport)\n",
                "    RETURN node.flight_number AS flight_number, node.fleet_type_description AS fleet_type_description,\n",
                "           origin.station_code AS origin, dest.station_code AS destination, score\n",
                "    ORDER BY score DESC\n",
                "    \"\"\"\n",
                "    with driver.session() as session:\n",
                "        result = session.run(search_query, top_k=top_k, query_embedding=query_embedding)\n",
                "        return [{**dict(r), \"similarity_score\": r[\"score\"]} for r in result]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 141,
            "id": "embedding-helpers",
            "metadata": {},
            "outputs": [],
            "source": [
                "def format_embedding_results(results: List[Dict], node_type: str = \"Journey\") -> str:\n",
                "    \"\"\"Format embedding search results as context with enriched info.\"\"\"\n",
                "    if not results:\n",
                "        return f\"No similar {node_type} nodes found.\"\n",
                "    \n",
                "    lines = [f\"Found {len(results)} relevant {node_type} records:\"]\n",
                "    for i, r in enumerate(results, 1):\n",
                "        if node_type == \"Journey\":\n",
                "            # Rich journey text with all connected info\n",
                "            text = create_journey_text(r)\n",
                "        else:\n",
                "            text = create_flight_text({\"flight_number\": r.get(\"flight_number\"), \n",
                "                                       \"fleet_type_description\": r.get(\"fleet_type_description\")},\n",
                "                                      r.get(\"origin\"), r.get(\"destination\"))\n",
                "        lines.append(f\"  {i}. (score: {r['similarity_score']:.3f}) {text}\")\n",
                "    return \"\\n\".join(lines)\n",
                "\n",
                "\n",
                "def get_embedding_context(driver: Driver, query: str, model_key: str = \"minilm\", top_k: int = 5) -> str:\n",
                "    \"\"\"Get context from embedding-based semantic search.\"\"\"\n",
                "    contexts = []\n",
                "    try:\n",
                "        contexts.append(format_embedding_results(semantic_search_journeys(driver, query, model_key, top_k), \"Journey\"))\n",
                "    except Exception as e:\n",
                "        contexts.append(f\"Journey search error: {e}\")\n",
                "    try:\n",
                "        contexts.append(format_embedding_results(semantic_search_flights(driver, query, model_key, top_k), \"Flight\"))\n",
                "    except Exception as e:\n",
                "        contexts.append(f\"Flight search error: {e}\")\n",
                "    return \"\\n\\n\".join(contexts)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 142,
            "id": "generate-all-embeddings",
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_and_store_all_embeddings(driver: Driver, model_key: str = \"minilm\"):\n",
                "    \"\"\"Generate and store embeddings for all Journey and Flight nodes.\"\"\"\n",
                "    print(f\"\\n{'='*60}\")\n",
                "    print(f\"Generating embeddings with {EMBEDDING_MODELS[model_key]['name']}\")\n",
                "    print(f\"{'='*60}\\n\")\n",
                "    \n",
                "    # Journeys\n",
                "    print(\"Fetching Journey nodes...\")\n",
                "    journeys = fetch_journey_nodes(driver)\n",
                "    print(f\"Found {len(journeys)} journeys\")\n",
                "    \n",
                "    if journeys:\n",
                "        texts = [create_journey_text(j[\"properties\"]) for j in journeys]\n",
                "        embeddings = generate_embeddings(texts, model_key)\n",
                "        create_vector_index(driver, model_key, \"Journey\")\n",
                "        store_journey_embeddings(driver, [j[\"feedback_ID\"] for j in journeys], embeddings, model_key)\n",
                "    \n",
                "    # Flights\n",
                "    print(\"\\nFetching Flight nodes...\")\n",
                "    flights = fetch_flight_nodes(driver)\n",
                "    print(f\"Found {len(flights)} flights\")\n",
                "    \n",
                "    if flights:\n",
                "        texts = [create_flight_text(f[\"properties\"], f[\"origin\"], f[\"destination\"]) for f in flights]\n",
                "        embeddings = generate_embeddings(texts, model_key)\n",
                "        create_vector_index(driver, model_key, \"Flight\")\n",
                "        store_flight_embeddings(driver, flights, embeddings, model_key)\n",
                "    \n",
                "    print(f\"\\nEmbedding generation complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "section-5",
            "metadata": {},
            "source": [
                "## 5. Hybrid Retrieval\n",
                "\n",
                "Combines Cypher queries with embedding-based semantic search."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 143,
            "id": "hybrid-context",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_hybrid_context(driver: Driver, prompt: str, model_key: str = \"minilm\", top_k: int = 3) -> Dict[str, Any]:\n",
                "    \"\"\"Get context from both Cypher queries and embedding search.\"\"\"\n",
                "    results = {'cypher_context': [], 'embedding_context': '', 'combined_context': ''}\n",
                "    \n",
                "    # Cypher context\n",
                "    try:\n",
                "        for cq in get_context(prompt):\n",
                "            results['cypher_context'].append(format_query_result(cq['query_index'], **cq['params']))\n",
                "    except Exception as e:\n",
                "        results['cypher_context'].append(f\"Cypher error: {e}\")\n",
                "    \n",
                "    # Embedding context\n",
                "    try:\n",
                "        results['embedding_context'] = get_embedding_context(driver, prompt, model_key, top_k)\n",
                "    except Exception as e:\n",
                "        results['embedding_context'] = f\"Embedding error: {e}\"\n",
                "    \n",
                "    # Combine\n",
                "    cypher_text = '\\n\\n'.join(results['cypher_context'])\n",
                "    results['combined_context'] = f\"=== STRUCTURED QUERY RESULTS ===\\n{cypher_text}\\n\\n=== SEMANTIC SEARCH RESULTS ===\\n{results['embedding_context']}\"\n",
                "    \n",
                "    return results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 144,
            "id": "answer-hybrid",
            "metadata": {},
            "outputs": [],
            "source": [
                "def answer_with_hybrid_context(driver: Driver, question: str, model_key: str = \"minilm\") -> str:\n",
                "    \"\"\"Answer a question using hybrid retrieval.\"\"\"\n",
                "    context = get_hybrid_context(driver, question, model_key, top_k=5)['combined_context']\n",
                "    \n",
                "    prompt = f\"\"\"You are an AI assistant for an airline company analyzing flight data.\n",
                "\n",
                "Based on this context from our knowledge graph, answer the user's question.\n",
                "Only use information from the context. If insufficient, say so.\n",
                "\n",
                "CONTEXT:\n",
                "{context}\n",
                "\n",
                "USER QUESTION: {question}\n",
                "\n",
                "ANSWER:\"\"\"\n",
                "    \n",
                "    return llm.invoke(prompt).content"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 145,
            "id": "compare-methods",
            "metadata": {},
            "outputs": [],
            "source": [
                "def compare_retrieval_methods(driver: Driver, question: str) -> Dict[str, Any]:\n",
                "    \"\"\"Compare results from different retrieval methods.\"\"\"\n",
                "    results = {'cypher_only': [], 'embedding_minilm': '', 'embedding_mpnet': '', \n",
                "               'hybrid_minilm': None, 'hybrid_mpnet': None}\n",
                "    \n",
                "    # Cypher only\n",
                "    try:\n",
                "        for cq in get_context(question):\n",
                "            results['cypher_only'].append(format_query_result(cq['query_index'], **cq['params']))\n",
                "    except Exception as e:\n",
                "        results['cypher_only'] = [f\"Error: {e}\"]\n",
                "    \n",
                "    # Embeddings\n",
                "    for key in ['minilm', 'mpnet']:\n",
                "        try:\n",
                "            results[f'embedding_{key}'] = get_embedding_context(driver, question, key, 5)\n",
                "        except Exception as e:\n",
                "            results[f'embedding_{key}'] = f\"Error: {e}\"\n",
                "    \n",
                "    # Hybrid\n",
                "    results['hybrid_minilm'] = get_hybrid_context(driver, question, \"minilm\", 5)\n",
                "    results['hybrid_mpnet'] = get_hybrid_context(driver, question, \"mpnet\", 5)\n",
                "    \n",
                "    return results\n",
                "\n",
                "\n",
                "def print_comparison(results: Dict[str, Any]):\n",
                "    \"\"\"Print comparison results.\"\"\"\n",
                "    print(\"=\" * 80 + \"\\nRETRIEVAL METHOD COMPARISON\\n\" + \"=\" * 80)\n",
                "    print(\"\\n--- CYPHER ONLY ---\")\n",
                "    for ctx in results['cypher_only']: print(ctx + \"\\n\")\n",
                "    print(\"\\n--- EMBEDDING (MiniLM) ---\\n\" + results['embedding_minilm'])\n",
                "    print(\"\\n--- EMBEDDING (MPNet) ---\\n\" + results['embedding_mpnet'])\n",
                "    if results['hybrid_minilm']:\n",
                "        print(\"\\n--- HYBRID (MiniLM) ---\\n\" + results['hybrid_minilm']['combined_context'])\n",
                "    if results['hybrid_mpnet']:\n",
                "        print(\"\\n--- HYBRID (MPNet) ---\\n\" + results['hybrid_mpnet']['combined_context'])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "section-6",
            "metadata": {},
            "source": [
                "## 6. Interactive Q&A"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 146,
            "id": "ask-function",
            "metadata": {},
            "outputs": [],
            "source": [
                "def ask(question: str, use_hybrid: bool = True, model_key: str = \"minilm\") -> str:\n",
                "    \"\"\"Ask a question using the full pipeline.\"\"\"\n",
                "    print(f\"\\n{'='*60}\\nQ: {question}\\nMode: {'Hybrid' if use_hybrid else 'Cypher Only'}\\n{'='*60}\\n\")\n",
                "    \n",
                "    if use_hybrid:\n",
                "        answer = answer_with_hybrid_context(driver, question, model_key)\n",
                "    else:\n",
                "        context_parts = [format_query_result(cq['query_index'], **cq['params']) for cq in get_context(question)]\n",
                "        print({chr(10).join(context_parts)})\n",
                "        prompt = f\"\"\"You are an AI assistant for an airline analyzing flight data.\n",
                "Answer using only this context:\n",
                "\n",
                "{chr(10).join(context_parts)}\n",
                "\n",
                "Question: {question}\n",
                "\n",
                "Answer:\"\"\"\n",
                "        answer = llm.invoke(prompt).content\n",
                "    \n",
                "    print(f\"ANSWER:\\n{'-'*40}\\n{answer}\\n\")\n",
                "    return answer"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "section-7-examples",
            "metadata": {},
            "source": [
                "## 7. Usage Examples"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 147,
            "id": "example-generate",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Uncomment the line above to generate embeddings.\n"
                    ]
                }
            ],
            "source": [
                "# Generate embeddings (run once)\n",
                "# generate_and_store_all_embeddings(driver, \"minilm\")\n",
                "\n",
                "print(\"Uncomment the line above to generate embeddings.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 150,
            "id": "example-questions",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "============================================================\n",
                        "Q: What are the top 5 airports with the most delays?\n",
                        "Mode: Hybrid\n",
                        "============================================================\n",
                        "\n",
                        "ANSWER:\n",
                        "----------------------------------------\n",
                        "Based on the provided data, the top 5 airports with the most delays are:\n",
                        "\n",
                        "1. CDX (991 delay minutes)\n",
                        "2. JAX (810 delay minutes)\n",
                        "3. SIX (661 delay minutes)\n",
                        "4. FRX (462 delay minutes)\n",
                        "5. MUX (326 delay minutes) \n",
                        "\n",
                        "\n",
                        "\n",
                        "============================================================\n",
                        "Q: How do Millennials travel compared to Baby Boomers?\n",
                        "Mode: Hybrid\n",
                        "============================================================\n",
                        "\n",
                        "ANSWER:\n",
                        "----------------------------------------\n",
                        "The provided text does not contain information about how Millennials travel compared to Baby Boomers.  It does, however, provide examples of journeys with specific travel class, aircraft type, and traveler age group. \n",
                        "\n",
                        "\n",
                        "\n",
                        "============================================================\n",
                        "Q: Which aircraft type has the best on-time performance?\n",
                        "Mode: Hybrid\n",
                        "============================================================\n",
                        "\n",
                        "ANSWER:\n",
                        "----------------------------------------\n",
                        "The answer cannot be determined from the provided data. The query asks for the aircraft type with the LOWEST average arrival delay, but the data only shows the average delay by aircraft type. There is no information about on-time performance. \n",
                        "\n",
                        "\n",
                        "\n",
                        "============================================================\n",
                        "Q: What is the flight number of the journey that departs from LAX and arrives at IAX and has generation 'Millennials'?\n",
                        "Mode: Hybrid\n",
                        "============================================================\n",
                        "\n",
                        "ANSWER:\n",
                        "----------------------------------------\n",
                        "The flight number of the journey that departs from LAX and arrives at IAX and has a generation of Millennials is not provided in the context. \n",
                        "\n",
                        "\n",
                        "\n",
                        "============================================================\n",
                        "Q: What are the different loyalty program levels for a journey that has flight number 2, mention all of them\n",
                        "Mode: Hybrid\n",
                        "============================================================\n",
                        "\n",
                        "ANSWER:\n",
                        "----------------------------------------\n",
                        "The context does not list any loyalty programs for the journey with flight number 2. \n",
                        "\n",
                        "\n",
                        "Uncomment an example to try the pipeline!\n"
                    ]
                }
            ],
            "source": [
                "# Example questions:\n",
                "ask(\"What are the top 5 airports with the most delays?\")\n",
                "ask(\"How do Millennials travel compared to Baby Boomers?\")\n",
                "ask(\"Which aircraft type has the best on-time performance?\")\n",
                "ask(\"What is the flight number of the journey that departs from LAX and arrives at IAX and has generation 'Millennials'?\")\n",
                "ask(\"What are the different loyalty program levels for a journey that has flight number 2, mention all of them\")\n",
                "\n",
                "print(\"Uncomment an example to try the pipeline!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 149,
            "id": "cleanup",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Close driver when done\n",
                "# driver.close()\n",
                "# print(\"Closed.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}