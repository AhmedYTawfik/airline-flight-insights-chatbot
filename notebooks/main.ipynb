{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# Airline Flight Insights - Neo4j Database Connection\n",
                "\n",
                "This notebook connects to the Neo4j database and provides utilities to run predefined queries."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "imports",
            "metadata": {},
            "outputs": [
                {
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'neo4j'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mneo4j\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GraphDatabase\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv, find_dotenv\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_google_genai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGoogleGenerativeAI\n",
                        "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'neo4j'"
                    ]
                }
            ],
            "source": [
                "from neo4j import GraphDatabase\n",
                "from dotenv import load_dotenv, find_dotenv\n",
                "from langchain_google_genai import ChatGoogleGenerativeAI\n",
                "import os\n",
                "import json\n",
                "import re"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "env-loader",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load environment variables from .env file\n",
                "load_dotenv(find_dotenv())\n",
                "\n",
                "# Get Neo4j connection details from environment\n",
                "NEO4J_URI = os.getenv('NEO4J_URI') or os.getenv('URI')\n",
                "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME') or os.getenv('USERNAME')\n",
                "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD') or os.getenv('PASSWORD')\n",
                "\n",
                "# Get Google API key for Gemini\n",
                "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
                "\n",
                "print(f\"Loaded config for URI: {NEO4J_URI}\")\n",
                "print(f\"Google API key loaded: {'Yes' if google_api_key else 'No'}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "driver-setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create Neo4j driver\n",
                "driver = GraphDatabase.driver(\n",
                "    NEO4J_URI,\n",
                "    auth=(NEO4J_USERNAME, NEO4J_PASSWORD)\n",
                ")\n",
                "\n",
                "# Verify connection\n",
                "driver.verify_connectivity()\n",
                "print(\"Successfully connected to Neo4j database!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "llm-setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup Gemini LLM model (using gemini-2.5-flash)\n",
                "llm = ChatGoogleGenerativeAI(\n",
                "    model=\"gemini-2.5-flash\",\n",
                "    google_api_key=google_api_key,\n",
                "    temperature=0  # Lower temperature for more deterministic JSON output\n",
                ")\n",
                "print(\"Gemini LLM model loaded successfully!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "queries-list",
            "metadata": {},
            "outputs": [],
            "source": [
                "queries = [\n",
                "    # Intent 1: Operational Delay Diagnostics\n",
                "    \"MATCH (j:Journey)-[:ON]->(f:Flight)-[:ARRIVES_AT]->(a:Airport) RETURN a.station_code AS destination, SUM(j.arrival_delay_minutes) AS total_delay ORDER BY total_delay DESC LIMIT $x\",\n",
                "    \"MATCH (j:Journey)-[:ON]->(f:Flight)-[:ARRIVES_AT]->(a:Airport) RETURN a.station_code AS destination, SUM(j.arrival_delay_minutes) AS total_delay ORDER BY total_delay ASC LIMIT $x\",\n",
                "    \"MATCH (j:Journey)-[:ON]->(f:Flight)-[:DEPARTS_FROM]->(a:Airport) RETURN a.station_code AS origin, SUM(j.arrival_delay_minutes) AS total_delay ORDER BY total_delay DESC LIMIT $x\",\n",
                "    \"MATCH (j:Journey)-[:ON]->(f:Flight)-[:DEPARTS_FROM]->(a:Airport) RETURN a.station_code AS origin, SUM(j.arrival_delay_minutes) AS total_delay ORDER BY total_delay ASC LIMIT $x\",\n",
                "    \"MATCH (o:Airport {station_code: $origin_station_code})<-[:DEPARTS_FROM]-(f:Flight)-[:ARRIVES_AT]->(d:Airport), (j:Journey)-[:ON]->(f) WITH o, d, AVG(j.arrival_delay_minutes) AS avg_delay WHERE avg_delay > $x RETURN o.station_code AS origin, d.station_code AS destination, avg_delay\",\n",
                "    \"MATCH (j:Journey {number_of_legs: $x}) RETURN AVG(j.arrival_delay_minutes) AS avg_delay\",\n",
                "\n",
                "    # Intent 2: Service Quality & Product Optimization\n",
                "    \"MATCH (o:Airport)<-[:DEPARTS_FROM]-(f:Flight)-[:ARRIVES_AT]->(d:Airport), (j:Journey {passenger_class: $class_name})-[:ON]->(f) WITH o, d, AVG(j.food_satisfaction_score) AS avg_food_score WHERE avg_food_score < $threshold RETURN o.station_code AS origin, d.station_code AS destination, avg_food_score\",\n",
                "    \"MATCH (j:Journey {food_satisfaction_score: 1})-[:ON]->(f:Flight) WHERE j.actual_flown_miles > $x RETURN DISTINCT f.flight_number\",\n",
                "\n",
                "    # Intent 3: Fleet Performance Monitoring\n",
                "    \"MATCH (j:Journey)-[:ON]->(f:Flight) WHERE j.arrival_delay_minutes > $x RETURN f.fleet_type_description AS aircraft_type, COUNT(j) AS delay_frequency ORDER BY delay_frequency DESC LIMIT 1\",\n",
                "    \"MATCH (j:Journey)-[:ON]->(f:Flight {fleet_type_description: $x}) RETURN AVG(j.food_satisfaction_score) AS avg_food_score\",\n",
                "    \"MATCH (j:Journey)-[:ON]->(f:Flight {fleet_type_description: $x}) RETURN AVG(j.actual_flown_miles) AS avg_miles\",\n",
                "    \"MATCH (j:Journey)-[:ON]->(f:Flight {fleet_type_description: $x}) WITH COUNT(j) AS total_flights, COUNT(CASE WHEN j.arrival_delay_minutes < 0 THEN 1 END) AS early_flights RETURN (TOFLOAT(early_flights) / total_flights) * 100 AS early_arrival_percentage\",\n",
                "\n",
                "    # Intent 4: High-Value Customer (Loyalty) Retention\n",
                "    \"MATCH (p:Passenger {loyalty_program_level: $loyalty_program_level})-[:TOOK]->(j:Journey) RETURN AVG(j.arrival_delay_minutes) AS avg_delay\",\n",
                "    \"MATCH (p:Passenger {loyalty_program_level: $loyalty_program_level})-[:TOOK]->(j:Journey) WHERE j.arrival_delay_minutes > $x RETURN p.record_locator AS passenger_id, j.arrival_delay_minutes AS delay\",\n",
                "\n",
                "    # Intent 5: Demographic Market Analysis\n",
                "    \"MATCH (p:Passenger {generation: $generation})-[:TOOK]->(j:Journey)-[:ON]->(f:Flight) WHERE j.actual_flown_miles > $threshold RETURN f.fleet_type_description AS aircraft_type, COUNT(f) AS usage_count ORDER BY usage_count DESC LIMIT 1\",\n",
                "    \"MATCH (p:Passenger {generation: $generation})-[:TOOK]->(j:Journey)-[:ON]->(f:Flight) RETURN f.fleet_type_description AS fleet_type, COUNT(f) AS usage_count ORDER BY usage_count DESC LIMIT 1\",\n",
                "    \"MATCH (p:Passenger {generation: $generation})-[:TOOK]->(j:Journey)-[:ON]->(f:Flight)-[:ARRIVES_AT]->(a:Airport) RETURN a.station_code AS destination, COUNT(p) AS passenger_volume ORDER BY passenger_volume DESC LIMIT $x\"\n",
                "]\n",
                "\n",
                "query_descriptions = [\n",
                "    # Intent 1: Operational Delay Diagnostics\n",
                "    \"Identify the top ${x} destination stations with the highest accumulated arrival delay minutes.\",\n",
                "    \"Identify the top ${x} destination stations with the lowest accumulated arrival delay minutes.\",\n",
                "    \"Identify the top ${x} origin stations with the highest accumulated arrival delay minutes.\",\n",
                "    \"Identify the top ${x} origin stations with the lowest accumulated arrival delay minutes.\",\n",
                "    \"Find routes from the origin station ${origin_station_code} where the average arrival delay exceeds ${x} minutes.\",\n",
                "    \"Calculate the average arrival delay for flights consisting of exactly ${x} legs.\",\n",
                "\n",
                "    # Intent 2: Service Quality & Product Optimization\n",
                "    \"Identify routes for the passenger class ${class_name} where the average food satisfaction score is below ${threshold}.\",\n",
                "    \"List the flight numbers for journeys longer than ${x} miles where the food satisfaction score was 1.\",\n",
                "\n",
                "    # Intent 3: Fleet Performance Monitoring\n",
                "    \"Identify the aircraft type that has the highest frequency of arrival delays greater than ${x} minutes.\",\n",
                "    \"Calculate the average food satisfaction score for passengers flying on the ${x} fleet.\",\n",
                "    \"Calculate the average actual flown miles for the ${x} fleet.\",\n",
                "    \"Calculate the percentage of early arrivals for the ${x} fleet.\",\n",
                "\n",
                "    # Intent 4: High-Value Customer (Loyalty) Retention\n",
                "    \"Calculate the average arrival delay experienced by passengers with the loyalty level ${loyalty_program_level}.\",\n",
                "    \"Find the record locators for passengers with loyalty level ${loyalty_program_level} who experienced a delay greater than ${x} minutes.\",\n",
                "\n",
                "    # Intent 5: Demographic Market Analysis\n",
                "    \"Identify the most common aircraft type used by the ${generation} generation for journeys exceeding ${threshold} miles.\",\n",
                "    \"Identify the most frequently used fleet type for the ${generation} generation.\",\n",
                "    \"Identify the top ${x} destination stations for the ${generation} generation based on passenger volume.\"\n",
                "]\n",
                "\n",
                "print(f\"Loaded {len(queries)} queries\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "run-query-function",
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_query(query_index: int, **params) -> list:\n",
                "    \"\"\"\n",
                "    Run a query from the queries list by index with the provided parameters.\n",
                "    \n",
                "    Args:\n",
                "        query_index: The index of the query in the queries list (0-based)\n",
                "        **params: Keyword arguments for query parameters (e.g., x=5, origin_station_code='LAX')\n",
                "    \n",
                "    Returns:\n",
                "        List of records as dictionaries\n",
                "    \"\"\"\n",
                "    if query_index < 0 or query_index >= len(queries):\n",
                "        raise ValueError(f\"Query index {query_index} is out of range. Valid range: 0-{len(queries)-1}\")\n",
                "    \n",
                "    query = queries[query_index]\n",
                "    \n",
                "    with driver.session() as session:\n",
                "        result = session.run(query, **params)\n",
                "        records = [record.data() for record in result]\n",
                "    \n",
                "    return records"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "llm-context-header",
            "metadata": {},
            "source": [
                "## LLM-Powered Context Retrieval\n",
                "\n",
                "The following functions use Gemini to intelligently select relevant queries based on user prompts and format results as context."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "get-context-function",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_context(prompt: str) -> list:\n",
                "    \"\"\"\n",
                "    Use Gemini LLM to identify relevant queries and extract parameters from user prompt.\n",
                "    \n",
                "    Args:\n",
                "        prompt: User's natural language question\n",
                "        \n",
                "    Returns:\n",
                "        List of dicts with 'query_index' and 'params' keys\n",
                "    \"\"\"\n",
                "    # Build query descriptions with readable parameter placeholders\n",
                "    safe_descriptions = [desc.replace('${', '<').replace('}', '>') for desc in query_descriptions]\n",
                "    query_list = \"\\n\".join([f\"{i}: {desc}\" for i, desc in enumerate(safe_descriptions)])\n",
                "    num_queries = len(queries) - 1\n",
                "    \n",
                "    # Build prompt using string concatenation to avoid f-string escaping issues\n",
                "    full_prompt = (\n",
                "        \"You are an expert at analyzing user questions about airline flight data and matching them to database queries.\\n\\n\"\n",
                "        \"Available queries (index: description):\\n\"\n",
                "        + query_list + \"\\n\\n\"\n",
                "        \"Your task:\\n\"\n",
                "        \"1. Analyze the user's question below\\n\"\n",
                "        \"2. Identify which query indices (0-\" + str(num_queries) + \") would provide useful context\\n\"\n",
                "        \"3. Extract ALL required parameters from the question for each query\\n\\n\"\n",
                "        \"Parameter reference (shown as <param_name> in queries):\\n\"\n",
                "        \"- x: a number (count, limit, threshold). Default: 5 for counts, 30 for delays\\n\"\n",
                "        \"- origin_station_code: airport code like 'LAX', 'ORD', 'JFK'\\n\"\n",
                "        \"- class_name: 'Economy', 'Business', or 'First'\\n\"\n",
                "        \"- threshold: numeric value. Default: 1000 for miles\\n\"\n",
                "        \"- loyalty_program_level: 'Gold', 'Silver', 'Platinum'\\n\"\n",
                "        \"- generation: 'Millennial', 'Gen X', 'Baby Boomer', 'Gen Z'\\n\\n\"\n",
                "        'CRITICAL: Return ONLY a valid JSON array. No markdown, no explanation.\\n'\n",
                "        'Format: [{\"query_index\": 0, \"params\": {\"x\": 3}}]\\n\\n'\n",
                "        \"User question: \" + prompt + \"\\n\\n\"\n",
                "        \"JSON response:\"\n",
                "    )\n",
                "\n",
                "    # Use Gemini to get the response\n",
                "    response = llm.invoke(full_prompt)\n",
                "    response_text = response.content.strip()\n",
                "    \n",
                "    # Clean up response - remove markdown code blocks if present\n",
                "    response_text = response_text.replace('```json', '').replace('```', '').strip()\n",
                "    \n",
                "    # Try to find and parse JSON array\n",
                "    json_match = re.search(r'\\[.*\\]', response_text, re.DOTALL)\n",
                "    if json_match:\n",
                "        try:\n",
                "            result = json.loads(json_match.group())\n",
                "            return result\n",
                "        except json.JSONDecodeError as e:\n",
                "            print(f\"JSON parse error: {e}\")\n",
                "            print(f\"Attempted to parse: {json_match.group()[:200]}\")\n",
                "    \n",
                "    print(f\"Warning: Could not parse LLM response: {response_text[:300]}\")\n",
                "    return []"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "format-query-result-function",
            "metadata": {},
            "outputs": [],
            "source": [
                "def format_query_result(query_index: int, **params) -> str:\n",
                "    \"\"\"\n",
                "    Run a query and format the result as context.\n",
                "    \n",
                "    Args:\n",
                "        query_index: Index of the query to run\n",
                "        **params: Parameters for the query\n",
                "        \n",
                "    Returns:\n",
                "        Formatted string with query description and results\n",
                "    \"\"\"\n",
                "    if query_index < 0 or query_index >= len(queries):\n",
                "        return f\"Error: Query index {query_index} is out of range.\"\n",
                "    \n",
                "    # Get the description and fill in parameters\n",
                "    description = query_descriptions[query_index]\n",
                "    for param_name, param_value in params.items():\n",
                "        description = description.replace(f\"${{{param_name}}}\", str(param_value))\n",
                "    \n",
                "    # Run the query\n",
                "    try:\n",
                "        results = run_query(query_index, **params)\n",
                "    except Exception as e:\n",
                "        return f\"The answer for \\\"{description}\\\" could not be retrieved due to an error: {str(e)}\"\n",
                "    \n",
                "    # Format the results\n",
                "    if not results:\n",
                "        return f\"The answer for \\\"{description}\\\" is: No data found.\"\n",
                "    \n",
                "    formatted_results = []\n",
                "    for record in results:\n",
                "        parts = []\n",
                "        for key, value in record.items():\n",
                "            if isinstance(value, float):\n",
                "                parts.append(f\"{key}: {value:.2f}\")\n",
                "            else:\n",
                "                parts.append(f\"{key}: {value}\")\n",
                "        formatted_results.append(\"  - \" + \", \".join(parts))\n",
                "    \n",
                "    result_text = \"\\n\".join(formatted_results)\n",
                "    return f\"The answer for \\\"{description}\\\" is:\\n{result_text}\""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "examples-header",
            "metadata": {},
            "source": [
                "## Example: Using LLM Context Functions\n",
                "\n",
                "The following cells demonstrate how to use `get_context` and `format_query_result`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "example-context",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example: Get context for a user question\n",
                "user_question = \"What are the top 3 airports with the most delays?\"\n",
                "\n",
                "print(f\"User question: {user_question}\\n\")\n",
                "print(\"Analyzing question with Gemini LLM...\\n\")\n",
                "\n",
                "# Get relevant queries and parameters\n",
                "context_queries = get_context(user_question)\n",
                "print(f\"Identified queries: {context_queries}\\n\")\n",
                "\n",
                "# Format each result as context\n",
                "print(\"=\" * 60)\n",
                "print(\"RETRIEVED CONTEXT:\")\n",
                "print(\"=\" * 60)\n",
                "for cq in context_queries:\n",
                "    context = format_query_result(cq[\"query_index\"], **cq[\"params\"])\n",
                "    print(context)\n",
                "    print()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "example-context-2",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example 2: More complex question\n",
                "user_question = \"How do Millennials travel compared to Gen X? Show me top 5 destinations for each.\"\n",
                "\n",
                "print(f\"User question: {user_question}\\n\")\n",
                "print(\"Analyzing question with Gemini LLM...\\n\")\n",
                "\n",
                "context_queries = get_context(user_question)\n",
                "print(f\"Identified queries: {context_queries}\\n\")\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"RETRIEVED CONTEXT:\")\n",
                "print(\"=\" * 60)\n",
                "for cq in context_queries:\n",
                "    context = format_query_result(cq[\"query_index\"], **cq[\"params\"])\n",
                "    print(context)\n",
                "    print()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "legacy-examples-header",
            "metadata": {},
            "source": [
                "## Legacy Example Queries\n",
                "\n",
                "Direct query execution examples."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "example-usage",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example 1: Query 0 - Top destinations by total delay\n",
                "results = run_query(0, x=5)\n",
                "print(\"Top 5 destinations by total delay:\")\n",
                "for r in results:\n",
                "    print(f\"  {r['destination']}: {r['total_delay']} minutes\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cleanup",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Close driver when done (run this cell when finished)\n",
                "# driver.close()\n",
                "# print(\"Driver closed.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
