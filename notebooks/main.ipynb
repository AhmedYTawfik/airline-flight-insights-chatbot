{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# Airline Flight Insights - Full Pipeline\n",
                "\n",
                "This notebook provides a complete Graph-RAG pipeline including:\n",
                "1. **Neo4j Database Connection**\n",
                "2. **LLM Setup** (Gemini)\n",
                "3. **Embeddings** - Vector embeddings for semantic search\n",
                "4. **Hybrid Retrieval** - Cypher + Semantic search\n",
                "5. **Question Answering**"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "section-1",
            "metadata": {},
            "source": [
                "## 1. Imports and Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "from neo4j import GraphDatabase, Driver\n",
                "from dotenv import load_dotenv, find_dotenv\n",
                "from langchain_google_genai import ChatGoogleGenerativeAI\n",
                "from sentence_transformers import SentenceTransformer\n",
                "from typing import List, Dict, Any, Optional, Callable, Tuple\n",
                "import numpy as np\n",
                "import os\n",
                "import json"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "env-loader",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "URI: neo4j+s://d9ac65c9.databases.neo4j.io\n",
                        "Google API key loaded: Yes\n"
                    ]
                }
            ],
            "source": [
                "# Load environment variables\n",
                "load_dotenv(find_dotenv())\n",
                "\n",
                "NEO4J_URI = os.getenv('NEO4J_URI') or os.getenv('URI')\n",
                "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME') or os.getenv('USERNAME')\n",
                "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD') or os.getenv('PASSWORD')\n",
                "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
                "\n",
                "print(f\"URI: {NEO4J_URI}\")\n",
                "print(f\"Google API key loaded: {'Yes' if google_api_key else 'No'}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "driver-setup",
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'TRUST_ALL_CERTIFICATES' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create Neo4j driver\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD), encrypted=\u001b[38;5;28;01mFalse\u001b[39;00m, trust=\u001b[43mTRUST_ALL_CERTIFICATES\u001b[49m)\n\u001b[32m      3\u001b[39m driver.verify_connectivity()\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mConnected to Neo4j!\u001b[39m\u001b[33m\"\u001b[39m)\n",
                        "\u001b[31mNameError\u001b[39m: name 'TRUST_ALL_CERTIFICATES' is not defined"
                    ]
                }
            ],
            "source": [
                "# Create Neo4j driver\n",
                "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
                "driver.verify_connectivity()\n",
                "print(\"Connected to Neo4j!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "llm-setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup Gemini LLM\n",
                "llm = ChatGoogleGenerativeAI(\n",
                "    model=\"gemini-2.5-flash\",\n",
                "    google_api_key=google_api_key,\n",
                "    temperature=0\n",
                ")\n",
                "print(\"Gemini LLM loaded!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "section-2",
            "metadata": {},
            "source": [
                "## 2. Cypher Queries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "queries-list",
            "metadata": {},
            "outputs": [],
            "source": [
                "queries = [\n",
                "    # Intent 1: Operational Delay Diagnostics\n",
                "    \"MATCH (j:Journey)-[:ON]->(f:Flight)-[:ARRIVES_AT]->(a:Airport) RETURN a.station_code AS destination, SUM(j.arrival_delay_minutes) AS total_delay ORDER BY total_delay DESC LIMIT $x\",\n",
                "    \"MATCH (j:Journey)-[:ON]->(f:Flight)-[:ARRIVES_AT]->(a:Airport) RETURN a.station_code AS destination, SUM(j.arrival_delay_minutes) AS total_delay ORDER BY total_delay ASC LIMIT $x\",\n",
                "    \"MATCH (j:Journey)-[:ON]->(f:Flight)-[:DEPARTS_FROM]->(a:Airport) RETURN a.station_code AS origin, SUM(j.arrival_delay_minutes) AS total_delay ORDER BY total_delay DESC LIMIT $x\",\n",
                "    \"MATCH (j:Journey)-[:ON]->(f:Flight)-[:DEPARTS_FROM]->(a:Airport) RETURN a.station_code AS origin, SUM(j.arrival_delay_minutes) AS total_delay ORDER BY total_delay ASC LIMIT $x\",\n",
                "    \"MATCH (o:Airport {station_code: $origin_station_code})<-[:DEPARTS_FROM]-(f:Flight)-[:ARRIVES_AT]->(d:Airport), (j:Journey)-[:ON]->(f) WITH o, d, AVG(j.arrival_delay_minutes) AS avg_delay WHERE avg_delay > $x RETURN o.station_code AS origin, d.station_code AS destination, avg_delay\",\n",
                "    \"MATCH (j:Journey {number_of_legs: $x}) RETURN AVG(j.arrival_delay_minutes) AS avg_delay\",\n",
                "    # Intent 2: Service Quality\n",
                "    \"MATCH (o:Airport)<-[:DEPARTS_FROM]-(f:Flight)-[:ARRIVES_AT]->(d:Airport), (j:Journey {passenger_class: $class_name})-[:ON]->(f) WITH o, d, AVG(j.food_satisfaction_score) AS avg_food_score WHERE avg_food_score < $threshold RETURN o.station_code AS origin, d.station_code AS destination, avg_food_score\",\n",
                "    \"MATCH (j:Journey {food_satisfaction_score: 1})-[:ON]->(f:Flight) WHERE j.actual_flown_miles > $x RETURN DISTINCT f.flight_number\",\n",
                "    # Intent 3: Fleet Performance\n",
                "    \"MATCH (j:Journey)-[:ON]->(f:Flight) WHERE j.arrival_delay_minutes > $x RETURN f.fleet_type_description AS aircraft_type, COUNT(j) AS delay_frequency ORDER BY delay_frequency DESC LIMIT 1\",\n",
                "    \"MATCH (j:Journey)-[:ON]->(f:Flight {fleet_type_description: $x}) RETURN AVG(j.food_satisfaction_score) AS avg_food_score\",\n",
                "    \"MATCH (j:Journey)-[:ON]->(f:Flight {fleet_type_description: $x}) RETURN AVG(j.actual_flown_miles) AS avg_miles\",\n",
                "    \"MATCH (j:Journey)-[:ON]->(f:Flight {fleet_type_description: $x}) WITH COUNT(j) AS total_flights, COUNT(CASE WHEN j.arrival_delay_minutes < 0 THEN 1 END) AS early_flights RETURN (TOFLOAT(early_flights) / total_flights) * 100 AS early_arrival_percentage\",\n",
                "    # Intent 4: Loyalty\n",
                "    \"MATCH (p:Passenger {loyalty_program_level: $loyalty_program_level})-[:TOOK]->(j:Journey) RETURN AVG(j.arrival_delay_minutes) AS avg_delay\",\n",
                "    \"MATCH (p:Passenger {loyalty_program_level: $loyalty_program_level})-[:TOOK]->(j:Journey) WHERE j.arrival_delay_minutes > $x RETURN p.record_locator AS passenger_id, j.arrival_delay_minutes AS delay\",\n",
                "    # Intent 5: Demographics\n",
                "    \"MATCH (p:Passenger {generation: $generation})-[:TOOK]->(j:Journey)-[:ON]->(f:Flight) WHERE j.actual_flown_miles > $threshold RETURN f.fleet_type_description AS aircraft_type, COUNT(f) AS usage_count ORDER BY usage_count DESC LIMIT 1\",\n",
                "    \"MATCH (p:Passenger {generation: $generation})-[:TOOK]->(j:Journey)-[:ON]->(f:Flight) RETURN f.fleet_type_description AS fleet_type, COUNT(f) AS usage_count ORDER BY usage_count DESC LIMIT 1\",\n",
                "    \"MATCH (p:Passenger {generation: $generation})-[:TOOK]->(j:Journey)-[:ON]->(f:Flight)-[:ARRIVES_AT]->(a:Airport) RETURN a.station_code AS destination, COUNT(p) AS passenger_volume ORDER BY passenger_volume DESC LIMIT $x\"\n",
                "]\n",
                "\n",
                "query_descriptions = [\n",
                "    \"Identify the top ${x} destination stations with the highest accumulated arrival delay minutes.\",\n",
                "    \"Identify the top ${x} destination stations with the lowest accumulated arrival delay minutes.\",\n",
                "    \"Identify the top ${x} origin stations with the highest accumulated arrival delay minutes.\",\n",
                "    \"Identify the top ${x} origin stations with the lowest accumulated arrival delay minutes.\",\n",
                "    \"Find routes from the origin station ${origin_station_code} where the average arrival delay exceeds ${x} minutes.\",\n",
                "    \"Calculate the average arrival delay for flights consisting of exactly ${x} legs.\",\n",
                "    \"Identify routes for the passenger class ${class_name} where the average food satisfaction score is below ${threshold}.\",\n",
                "    \"List the flight numbers for journeys longer than ${x} miles where the food satisfaction score was 1.\",\n",
                "    \"Identify the aircraft type that has the highest frequency of arrival delays greater than ${x} minutes.\",\n",
                "    \"Calculate the average food satisfaction score for passengers flying on the ${x} fleet.\",\n",
                "    \"Calculate the average actual flown miles for the ${x} fleet.\",\n",
                "    \"Calculate the percentage of early arrivals for the ${x} fleet.\",\n",
                "    \"Calculate the average arrival delay experienced by passengers with the loyalty level ${loyalty_program_level}.\",\n",
                "    \"Find the record locators for passengers with loyalty level ${loyalty_program_level} who experienced a delay greater than ${x} minutes.\",\n",
                "    \"Identify the most common aircraft type used by the ${generation} generation for journeys exceeding ${threshold} miles.\",\n",
                "    \"Identify the most frequently used fleet type for the ${generation} generation.\",\n",
                "    \"Identify the top ${x} destination stations for the ${generation} generation based on passenger volume.\"\n",
                "]\n",
                "\n",
                "print(f\"Loaded {len(queries)} queries\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "section-3",
            "metadata": {},
            "source": [
                "## 3. Query Execution Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "run-query",
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_query(query_index: int, **params) -> list:\n",
                "    \"\"\"Run a query by index with parameters.\"\"\"\n",
                "    if query_index < 0 or query_index >= len(queries):\n",
                "        raise ValueError(f\"Query index {query_index} out of range (0-{len(queries)-1})\")\n",
                "    with driver.session() as session:\n",
                "        result = session.run(queries[query_index], **params)\n",
                "        return [record.data() for record in result]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "get-context",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_context(prompt: str) -> list:\n",
                "    \"\"\"Use Gemini to identify relevant queries and extract parameters.\"\"\"\n",
                "    safe_descriptions = [desc.replace('${', '<').replace('}', '>') for desc in query_descriptions]\n",
                "    query_list = \"\\n\".join([f\"{i}: {desc}\" for i, desc in enumerate(safe_descriptions)])\n",
                "    \n",
                "    full_prompt = (\n",
                "        \"You are an expert at analyzing user questions about airline flight data.\\n\\n\"\n",
                "        \"Available queries:\\n\" + query_list + \"\\n\\n\"\n",
                "        \"Your task:\\n\"\n",
                "        \"1. Identify which query indices (0-\" + str(len(queries)-1) + \") provide useful context\\n\"\n",
                "        \"2. Extract ALL required parameters\\n\\n\"\n",
                "        \"Parameters:\\n\"\n",
                "        \"- x: number (default: 5 for counts, 30 for delays)\\n\"\n",
                "        \"- origin_station_code: airport code like 'LAX'\\n\"\n",
                "        \"- class_name: 'Economy', 'Business', 'First'\\n\"\n",
                "        \"- threshold: numeric (default: 1000 for miles)\\n\"\n",
                "        \"- loyalty_program_level: 'Gold', 'Silver', 'Platinum'\\n\"\n",
                "        \"- generation: 'Millennial', 'Gen X', 'Baby Boomer', 'Gen Z'\\n\\n\"\n",
                "        'Return ONLY a valid JSON array: [{\"query_index\": 0, \"params\": {\"x\": 3}}]\\n\\n'\n",
                "        \"User question: \" + prompt + \"\\n\\nJSON:\"\n",
                "    )\n",
                "    \n",
                "    response = llm.invoke(full_prompt)\n",
                "    response_text = response.content.strip().replace('```json', '').replace('```', '').strip()\n",
                "    \n",
                "    json_match = re.search(r'\\[.*\\]', response_text, re.DOTALL)\n",
                "    if json_match:\n",
                "        try:\n",
                "            return json.loads(json_match.group())\n",
                "        except json.JSONDecodeError as e:\n",
                "            print(f\"JSON parse error: {e}\")\n",
                "    return []"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "format-result",
            "metadata": {},
            "outputs": [],
            "source": [
                "def format_query_result(query_index: int, **params) -> str:\n",
                "    \"\"\"Run query and format result as context.\"\"\"\n",
                "    if query_index < 0 or query_index >= len(queries):\n",
                "        return f\"Error: Query index {query_index} out of range.\"\n",
                "    \n",
                "    description = query_descriptions[query_index]\n",
                "    for name, value in params.items():\n",
                "        description = description.replace(f\"${{{name}}}\", str(value))\n",
                "    \n",
                "    try:\n",
                "        results = run_query(query_index, **params)\n",
                "    except Exception as e:\n",
                "        return f'Error for \"{description}\": {e}'\n",
                "    \n",
                "    if not results:\n",
                "        return f'\"{description}\": No data found.'\n",
                "    \n",
                "    formatted = []\n",
                "    for r in results:\n",
                "        parts = [f\"{k}: {v:.2f}\" if isinstance(v, float) else f\"{k}: {v}\" for k, v in r.items()]\n",
                "        formatted.append(\"  - \" + \", \".join(parts))\n",
                "    \n",
                "    return f'\"{description}\":\\n' + \"\\n\".join(formatted)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "section-4",
            "metadata": {},
            "source": [
                "## 4. Embeddings Module\n",
                "\n",
                "Vector embeddings for semantic search. Models:\n",
                "- `minilm`: all-MiniLM-L6-v2 (384 dims, fast)\n",
                "- `mpnet`: all-mpnet-base-v2 (768 dims, higher quality)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "embedding-config",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Embedding model configurations\n",
                "EMBEDDING_MODELS = {\n",
                "    \"minilm\": {\"name\": \"all-MiniLM-L6-v2\", \"dimensions\": 384, \"property_name\": \"embedding_minilm\"},\n",
                "    \"mpnet\": {\"name\": \"all-mpnet-base-v2\", \"dimensions\": 768, \"property_name\": \"embedding_mpnet\"}\n",
                "}\n",
                "\n",
                "_model_cache: Dict[str, SentenceTransformer] = {}\n",
                "\n",
                "def get_model(model_key: str) -> SentenceTransformer:\n",
                "    \"\"\"Load and cache an embedding model.\"\"\"\n",
                "    if model_key not in EMBEDDING_MODELS:\n",
                "        raise ValueError(f\"Unknown model: {model_key}. Use 'minilm' or 'mpnet'\")\n",
                "    if model_key not in _model_cache:\n",
                "        print(f\"Loading {EMBEDDING_MODELS[model_key]['name']}...\")\n",
                "        _model_cache[model_key] = SentenceTransformer(EMBEDDING_MODELS[model_key][\"name\"])\n",
                "        print(\"Model loaded!\")\n",
                "    return _model_cache[model_key]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "text-representations",
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_journey_text(props: Dict[str, Any]) -> str:\n",
                "    \"\"\"Create text representation of a Journey node.\"\"\"\n",
                "    passenger_class = props.get(\"passenger_class\", \"Unknown\")\n",
                "    food_score = props.get(\"food_satisfaction_score\", \"N/A\")\n",
                "    delay = props.get(\"arrival_delay_minutes\", 0)\n",
                "    miles = props.get(\"actual_flown_miles\", 0)\n",
                "    legs = props.get(\"number_of_legs\", 1)\n",
                "    \n",
                "    delay_text = f\"arrived {abs(delay)} minutes early\" if delay < 0 else \"on time\" if delay == 0 else f\"delayed {delay} minutes\"\n",
                "    food_labels = {1: \"very poor\", 2: \"poor\", 3: \"average\", 4: \"good\", 5: \"excellent\"}\n",
                "    satisfaction = food_labels.get(food_score, \"unknown\")\n",
                "    \n",
                "    return f\"A {passenger_class} class journey covering {miles:.0f} miles over {legs} segment{'s' if legs > 1 else ''}. Flight {delay_text}, {satisfaction} food satisfaction (score: {food_score}/5).\"\n",
                "\n",
                "\n",
                "def create_flight_text(props: Dict[str, Any], origin: str = None, destination: str = None) -> str:\n",
                "    \"\"\"Create text representation of a Flight node.\"\"\"\n",
                "    flight_num = props.get(\"flight_number\", \"Unknown\")\n",
                "    fleet = props.get(\"fleet_type_description\", \"Unknown aircraft\")\n",
                "    route = f\" from {origin} to {destination}\" if origin and destination else f\" from {origin}\" if origin else f\" to {destination}\" if destination else \"\"\n",
                "    return f\"Flight {flight_num} operated by {fleet}{route}.\"\n",
                "\n",
                "\n",
                "def create_passenger_text(props: Dict[str, Any]) -> str:\n",
                "    \"\"\"Create text representation of a Passenger node.\"\"\"\n",
                "    return f\"A {props.get('generation', 'unknown')} passenger with {props.get('loyalty_program_level', 'unknown')} loyalty status.\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "embedding-generation",
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_embeddings(texts: List[str], model_key: str = \"minilm\") -> np.ndarray:\n",
                "    \"\"\"Generate embeddings for a list of texts.\"\"\"\n",
                "    model = get_model(model_key)\n",
                "    return model.encode(texts, show_progress_bar=True, convert_to_numpy=True)\n",
                "\n",
                "\n",
                "def generate_single_embedding(text: str, model_key: str = \"minilm\") -> List[float]:\n",
                "    \"\"\"Generate embedding for a single text.\"\"\"\n",
                "    model = get_model(model_key)\n",
                "    return model.encode(text, convert_to_numpy=True).tolist()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "neo4j-fetch",
            "metadata": {},
            "outputs": [],
            "source": [
                "def fetch_journey_nodes(driver: Driver) -> List[Dict[str, Any]]:\n",
                "    \"\"\"Fetch all Journey nodes from Neo4j.\"\"\"\n",
                "    query = \"\"\"\n",
                "    MATCH (j:Journey)\n",
                "    RETURN j.feedback_ID AS feedback_ID, j.passenger_class AS passenger_class,\n",
                "           j.food_satisfaction_score AS food_satisfaction_score,\n",
                "           j.arrival_delay_minutes AS arrival_delay_minutes,\n",
                "           j.actual_flown_miles AS actual_flown_miles, j.number_of_legs AS number_of_legs\n",
                "    \"\"\"\n",
                "    with driver.session() as session:\n",
                "        result = session.run(query)\n",
                "        return [{\"feedback_ID\": r[\"feedback_ID\"], \"properties\": dict(r)} for r in result]\n",
                "\n",
                "\n",
                "def fetch_flight_nodes(driver: Driver) -> List[Dict[str, Any]]:\n",
                "    \"\"\"Fetch all Flight nodes from Neo4j with route info.\"\"\"\n",
                "    query = \"\"\"\n",
                "    MATCH (f:Flight)\n",
                "    OPTIONAL MATCH (f)-[:DEPARTS_FROM]->(origin:Airport)\n",
                "    OPTIONAL MATCH (f)-[:ARRIVES_AT]->(dest:Airport)\n",
                "    RETURN f.flight_number AS flight_number, f.fleet_type_description AS fleet_type_description,\n",
                "           origin.station_code AS origin, dest.station_code AS destination\n",
                "    \"\"\"\n",
                "    with driver.session() as session:\n",
                "        result = session.run(query)\n",
                "        return [{\n",
                "            \"flight_number\": r[\"flight_number\"],\n",
                "            \"fleet_type_description\": r[\"fleet_type_description\"],\n",
                "            \"properties\": {\"flight_number\": r[\"flight_number\"], \"fleet_type_description\": r[\"fleet_type_description\"]},\n",
                "            \"origin\": r[\"origin\"], \"destination\": r[\"destination\"]\n",
                "        } for r in result]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "vector-index",
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_vector_index(driver: Driver, model_key: str, node_label: str = \"Journey\"):\n",
                "    \"\"\"Create a vector index in Neo4j.\"\"\"\n",
                "    config = EMBEDDING_MODELS[model_key]\n",
                "    index_name = f\"{node_label.lower()}_{config['property_name']}\"\n",
                "    \n",
                "    create_query = f\"\"\"\n",
                "    CREATE VECTOR INDEX {index_name} IF NOT EXISTS\n",
                "    FOR (n:{node_label}) ON n.{config['property_name']}\n",
                "    OPTIONS {{indexConfig: {{\n",
                "        `vector.dimensions`: {config['dimensions']},\n",
                "        `vector.similarity_function`: 'cosine'\n",
                "    }}}}\n",
                "    \"\"\"\n",
                "    with driver.session() as session:\n",
                "        try:\n",
                "            session.run(f\"DROP INDEX {index_name} IF EXISTS\")\n",
                "        except: pass\n",
                "        session.run(create_query)\n",
                "        print(f\"Created index: {index_name}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "store-embeddings",
            "metadata": {},
            "outputs": [],
            "source": [
                "def store_journey_embeddings(driver: Driver, feedback_ids: List[str], embeddings: np.ndarray, \n",
                "                              model_key: str = \"minilm\", batch_size: int = 100):\n",
                "    \"\"\"Store embeddings for Journey nodes.\"\"\"\n",
                "    prop = EMBEDDING_MODELS[model_key][\"property_name\"]\n",
                "    query = f\"UNWIND $batch AS item MATCH (j:Journey {{feedback_ID: item.feedback_ID}}) SET j.{prop} = item.embedding\"\n",
                "    \n",
                "    with driver.session() as session:\n",
                "        for i in range(0, len(feedback_ids), batch_size):\n",
                "            batch = [{\"feedback_ID\": feedback_ids[j], \"embedding\": embeddings[j].tolist()} \n",
                "                     for j in range(i, min(i + batch_size, len(feedback_ids)))]\n",
                "            session.run(query, batch=batch)\n",
                "            print(f\"Stored {min(i + batch_size, len(feedback_ids))}/{len(feedback_ids)}...\")\n",
                "\n",
                "\n",
                "def store_flight_embeddings(driver: Driver, flights: List[Dict], embeddings: np.ndarray,\n",
                "                            model_key: str = \"minilm\", batch_size: int = 100):\n",
                "    \"\"\"Store embeddings for Flight nodes.\"\"\"\n",
                "    prop = EMBEDDING_MODELS[model_key][\"property_name\"]\n",
                "    query = f\"UNWIND $batch AS item MATCH (f:Flight {{flight_number: item.flight_number, fleet_type_description: item.fleet_type_description}}) SET f.{prop} = item.embedding\"\n",
                "    \n",
                "    with driver.session() as session:\n",
                "        for i in range(0, len(flights), batch_size):\n",
                "            batch = [{\"flight_number\": flights[j][\"flight_number\"], \n",
                "                      \"fleet_type_description\": flights[j][\"fleet_type_description\"],\n",
                "                      \"embedding\": embeddings[j].tolist()} \n",
                "                     for j in range(i, min(i + batch_size, len(flights)))]\n",
                "            session.run(query, batch=batch)\n",
                "            print(f\"Stored {min(i + batch_size, len(flights))}/{len(flights)}...\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "semantic-search",
            "metadata": {},
            "outputs": [],
            "source": [
                "def semantic_search_journeys(driver: Driver, query_text: str, model_key: str = \"minilm\", top_k: int = 5) -> List[Dict]:\n",
                "    \"\"\"Semantic search on Journey nodes.\"\"\"\n",
                "    query_embedding = generate_single_embedding(query_text, model_key)\n",
                "    index_name = f\"journey_{EMBEDDING_MODELS[model_key]['property_name']}\"\n",
                "    \n",
                "    search_query = f\"\"\"\n",
                "    CALL db.index.vector.queryNodes('{index_name}', $top_k, $query_embedding)\n",
                "    YIELD node, score\n",
                "    RETURN node.feedback_ID AS feedback_ID, node.passenger_class AS passenger_class,\n",
                "           node.food_satisfaction_score AS food_satisfaction_score,\n",
                "           node.arrival_delay_minutes AS arrival_delay_minutes,\n",
                "           node.actual_flown_miles AS actual_flown_miles, node.number_of_legs AS number_of_legs, score\n",
                "    ORDER BY score DESC\n",
                "    \"\"\"\n",
                "    with driver.session() as session:\n",
                "        result = session.run(search_query, top_k=top_k, query_embedding=query_embedding)\n",
                "        return [{**dict(r), \"similarity_score\": r[\"score\"]} for r in result]\n",
                "\n",
                "\n",
                "def semantic_search_flights(driver: Driver, query_text: str, model_key: str = \"minilm\", top_k: int = 5) -> List[Dict]:\n",
                "    \"\"\"Semantic search on Flight nodes.\"\"\"\n",
                "    query_embedding = generate_single_embedding(query_text, model_key)\n",
                "    index_name = f\"flight_{EMBEDDING_MODELS[model_key]['property_name']}\"\n",
                "    \n",
                "    search_query = f\"\"\"\n",
                "    CALL db.index.vector.queryNodes('{index_name}', $top_k, $query_embedding)\n",
                "    YIELD node, score\n",
                "    MATCH (node)-[:DEPARTS_FROM]->(origin:Airport)\n",
                "    MATCH (node)-[:ARRIVES_AT]->(dest:Airport)\n",
                "    RETURN node.flight_number AS flight_number, node.fleet_type_description AS fleet_type_description,\n",
                "           origin.station_code AS origin, dest.station_code AS destination, score\n",
                "    ORDER BY score DESC\n",
                "    \"\"\"\n",
                "    with driver.session() as session:\n",
                "        result = session.run(search_query, top_k=top_k, query_embedding=query_embedding)\n",
                "        return [{**dict(r), \"similarity_score\": r[\"score\"]} for r in result]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "embedding-helpers",
            "metadata": {},
            "outputs": [],
            "source": [
                "def format_embedding_results(results: List[Dict], node_type: str = \"Journey\") -> str:\n",
                "    \"\"\"Format embedding search results as context.\"\"\"\n",
                "    if not results:\n",
                "        return f\"No similar {node_type} nodes found.\"\n",
                "    \n",
                "    lines = [f\"Found {len(results)} similar {node_type} records:\"]\n",
                "    for i, r in enumerate(results, 1):\n",
                "        if node_type == \"Journey\":\n",
                "            text = create_journey_text(r)\n",
                "        else:\n",
                "            text = create_flight_text({\"flight_number\": r.get(\"flight_number\"), \n",
                "                                       \"fleet_type_description\": r.get(\"fleet_type_description\")},\n",
                "                                      r.get(\"origin\"), r.get(\"destination\"))\n",
                "        lines.append(f\"  {i}. (score: {r['similarity_score']:.3f}) {text}\")\n",
                "    return \"\\n\".join(lines)\n",
                "\n",
                "\n",
                "def get_embedding_context(driver: Driver, query: str, model_key: str = \"minilm\", top_k: int = 5) -> str:\n",
                "    \"\"\"Get context from embedding-based semantic search.\"\"\"\n",
                "    contexts = []\n",
                "    try:\n",
                "        contexts.append(format_embedding_results(semantic_search_journeys(driver, query, model_key, top_k), \"Journey\"))\n",
                "    except Exception as e:\n",
                "        contexts.append(f\"Journey search error: {e}\")\n",
                "    try:\n",
                "        contexts.append(format_embedding_results(semantic_search_flights(driver, query, model_key, top_k), \"Flight\"))\n",
                "    except Exception as e:\n",
                "        contexts.append(f\"Flight search error: {e}\")\n",
                "    return \"\\n\\n\".join(contexts)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "generate-all-embeddings",
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_and_store_all_embeddings(driver: Driver, model_key: str = \"minilm\"):\n",
                "    \"\"\"Generate and store embeddings for all Journey and Flight nodes.\"\"\"\n",
                "    print(f\"\\n{'='*60}\")\n",
                "    print(f\"Generating embeddings with {EMBEDDING_MODELS[model_key]['name']}\")\n",
                "    print(f\"{'='*60}\\n\")\n",
                "    \n",
                "    # Journeys\n",
                "    print(\"Fetching Journey nodes...\")\n",
                "    journeys = fetch_journey_nodes(driver)\n",
                "    print(f\"Found {len(journeys)} journeys\")\n",
                "    \n",
                "    if journeys:\n",
                "        texts = [create_journey_text(j[\"properties\"]) for j in journeys]\n",
                "        embeddings = generate_embeddings(texts, model_key)\n",
                "        create_vector_index(driver, model_key, \"Journey\")\n",
                "        store_journey_embeddings(driver, [j[\"feedback_ID\"] for j in journeys], embeddings, model_key)\n",
                "    \n",
                "    # Flights\n",
                "    print(\"\\nFetching Flight nodes...\")\n",
                "    flights = fetch_flight_nodes(driver)\n",
                "    print(f\"Found {len(flights)} flights\")\n",
                "    \n",
                "    if flights:\n",
                "        texts = [create_flight_text(f[\"properties\"], f[\"origin\"], f[\"destination\"]) for f in flights]\n",
                "        embeddings = generate_embeddings(texts, model_key)\n",
                "        create_vector_index(driver, model_key, \"Flight\")\n",
                "        store_flight_embeddings(driver, flights, embeddings, model_key)\n",
                "    \n",
                "    print(f\"\\nEmbedding generation complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "section-5",
            "metadata": {},
            "source": [
                "## 5. Hybrid Retrieval\n",
                "\n",
                "Combines Cypher queries with embedding-based semantic search."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "hybrid-context",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_hybrid_context(driver: Driver, prompt: str, model_key: str = \"minilm\", top_k: int = 3) -> Dict[str, Any]:\n",
                "    \"\"\"Get context from both Cypher queries and embedding search.\"\"\"\n",
                "    results = {'cypher_context': [], 'embedding_context': '', 'combined_context': ''}\n",
                "    \n",
                "    # Cypher context\n",
                "    try:\n",
                "        for cq in get_context(prompt):\n",
                "            results['cypher_context'].append(format_query_result(cq['query_index'], **cq['params']))\n",
                "    except Exception as e:\n",
                "        results['cypher_context'].append(f\"Cypher error: {e}\")\n",
                "    \n",
                "    # Embedding context\n",
                "    try:\n",
                "        results['embedding_context'] = get_embedding_context(driver, prompt, model_key, top_k)\n",
                "    except Exception as e:\n",
                "        results['embedding_context'] = f\"Embedding error: {e}\"\n",
                "    \n",
                "    # Combine\n",
                "    cypher_text = '\\n\\n'.join(results['cypher_context'])\n",
                "    results['combined_context'] = f\"=== STRUCTURED QUERY RESULTS ===\\n{cypher_text}\\n\\n=== SEMANTIC SEARCH RESULTS ===\\n{results['embedding_context']}\"\n",
                "    \n",
                "    return results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "answer-hybrid",
            "metadata": {},
            "outputs": [],
            "source": [
                "def answer_with_hybrid_context(driver: Driver, question: str, model_key: str = \"minilm\") -> str:\n",
                "    \"\"\"Answer a question using hybrid retrieval.\"\"\"\n",
                "    context = get_hybrid_context(driver, question, model_key, top_k=5)['combined_context']\n",
                "    \n",
                "    prompt = f\"\"\"You are an AI assistant for an airline company analyzing flight data.\n",
                "\n",
                "Based on this context from our knowledge graph, answer the user's question.\n",
                "Only use information from the context. If insufficient, say so.\n",
                "\n",
                "CONTEXT:\n",
                "{context}\n",
                "\n",
                "USER QUESTION: {question}\n",
                "\n",
                "ANSWER:\"\"\"\n",
                "    \n",
                "    return llm.invoke(prompt).content"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "compare-methods",
            "metadata": {},
            "outputs": [],
            "source": [
                "def compare_retrieval_methods(driver: Driver, question: str) -> Dict[str, Any]:\n",
                "    \"\"\"Compare results from different retrieval methods.\"\"\"\n",
                "    results = {'cypher_only': [], 'embedding_minilm': '', 'embedding_mpnet': '', \n",
                "               'hybrid_minilm': None, 'hybrid_mpnet': None}\n",
                "    \n",
                "    # Cypher only\n",
                "    try:\n",
                "        for cq in get_context(question):\n",
                "            results['cypher_only'].append(format_query_result(cq['query_index'], **cq['params']))\n",
                "    except Exception as e:\n",
                "        results['cypher_only'] = [f\"Error: {e}\"]\n",
                "    \n",
                "    # Embeddings\n",
                "    for key in ['minilm', 'mpnet']:\n",
                "        try:\n",
                "            results[f'embedding_{key}'] = get_embedding_context(driver, question, key, 5)\n",
                "        except Exception as e:\n",
                "            results[f'embedding_{key}'] = f\"Error: {e}\"\n",
                "    \n",
                "    # Hybrid\n",
                "    results['hybrid_minilm'] = get_hybrid_context(driver, question, \"minilm\", 5)\n",
                "    results['hybrid_mpnet'] = get_hybrid_context(driver, question, \"mpnet\", 5)\n",
                "    \n",
                "    return results\n",
                "\n",
                "\n",
                "def print_comparison(results: Dict[str, Any]):\n",
                "    \"\"\"Print comparison results.\"\"\"\n",
                "    print(\"=\" * 80 + \"\\nRETRIEVAL METHOD COMPARISON\\n\" + \"=\" * 80)\n",
                "    print(\"\\n--- CYPHER ONLY ---\")\n",
                "    for ctx in results['cypher_only']: print(ctx + \"\\n\")\n",
                "    print(\"\\n--- EMBEDDING (MiniLM) ---\\n\" + results['embedding_minilm'])\n",
                "    print(\"\\n--- EMBEDDING (MPNet) ---\\n\" + results['embedding_mpnet'])\n",
                "    if results['hybrid_minilm']:\n",
                "        print(\"\\n--- HYBRID (MiniLM) ---\\n\" + results['hybrid_minilm']['combined_context'])\n",
                "    if results['hybrid_mpnet']:\n",
                "        print(\"\\n--- HYBRID (MPNet) ---\\n\" + results['hybrid_mpnet']['combined_context'])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "section-6",
            "metadata": {},
            "source": [
                "## 6. Interactive Q&A"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ask-function",
            "metadata": {},
            "outputs": [],
            "source": [
                "def ask(question: str, use_hybrid: bool = True, model_key: str = \"minilm\") -> str:\n",
                "    \"\"\"Ask a question using the full pipeline.\"\"\"\n",
                "    print(f\"\\n{'='*60}\\nQ: {question}\\nMode: {'Hybrid' if use_hybrid else 'Cypher Only'}\\n{'='*60}\\n\")\n",
                "    \n",
                "    if use_hybrid:\n",
                "        answer = answer_with_hybrid_context(driver, question, model_key)\n",
                "    else:\n",
                "        context_parts = [format_query_result(cq['query_index'], **cq['params']) for cq in get_context(question)]\n",
                "        prompt = f\"\"\"You are an AI assistant for an airline analyzing flight data.\n",
                "Answer using only this context:\n",
                "\n",
                "{chr(10).join(context_parts)}\n",
                "\n",
                "Question: {question}\n",
                "\n",
                "Answer:\"\"\"\n",
                "        answer = llm.invoke(prompt).content\n",
                "    \n",
                "    print(f\"ANSWER:\\n{'-'*40}\\n{answer}\\n\")\n",
                "    return answer"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "section-7-examples",
            "metadata": {},
            "source": [
                "## 7. Usage Examples"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "example-generate",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate embeddings (run once)\n",
                "# generate_and_store_all_embeddings(driver, \"minilm\")\n",
                "\n",
                "print(\"Uncomment the line above to generate embeddings.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "example-questions",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example questions:\n",
                "ask(\"What are the top 5 airports with the most delays?\")\n",
                "ask(\"How do Millennials travel compared to Baby Boomers?\")\n",
                "ask(\"Which aircraft type has the best on-time performance?\")\n",
                "\n",
                "print(\"Uncomment an example to try the pipeline!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cleanup",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Close driver when done\n",
                "# driver.close()\n",
                "# print(\"Closed.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
