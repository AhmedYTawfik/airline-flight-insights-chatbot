{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 5,
         "id": "bc1374ed",
         "metadata": {},
         "outputs": [],
         "source": [
            "from langchain_core.prompts import ChatPromptTemplate\n",
            "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
            "from dotenv import load_dotenv\n",
            "import os\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "id": "bbcf45b7",
         "metadata": {},
         "outputs": [],
         "source": [
            "load_dotenv(\"../.env\")\n",
            "token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "id": "ef8be03c",
         "metadata": {},
         "outputs": [],
         "source": [
            "prompt_template = ChatPromptTemplate.from_messages([\n",
            "    (\"system\", \n",
            "    \"You are a helpful travel assistant.\\n\\n\"\n",
            "    \"Context:\\n{context}\"),\n",
            "    (\"human\",\n",
            "     \"Task:\\nAnswer the user's question using ONLY the provided context.\\n\"\n",
            "     \"If the answer is not present, say \\\"I don't have enough information.\\\"\\n\\n\"\n",
            "     \"User Question:\\n{question}\")\n",
            "])\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "id": "5b10e983",
         "metadata": {},
         "outputs": [],
         "source": [
            "base_models = {\n",
            "    \"Mistral\": HuggingFaceEndpoint(\n",
            "        repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
            "        huggingfacehub_api_token=token,\n",
            "    ),\n",
            "    \"Llama3\": HuggingFaceEndpoint(\n",
            "        repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
            "        huggingfacehub_api_token=token,\n",
            "    ),\n",
            "    \"Gemma\": HuggingFaceEndpoint(\n",
            "        repo_id=\"google/gemma-2-2b-it\",\n",
            "        huggingfacehub_api_token=token,\n",
            "    )\n",
            "}\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "id": "0750af24",
         "metadata": {},
         "outputs": [],
         "source": [
            "models = {\n",
            "    name: ChatHuggingFace(llm=llm)\n",
            "    for name, llm in base_models.items()\n",
            "}\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "id": "8b234773",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "\n",
                  "Mistral response:\n",
                  " I. Don't. Have. Enough. Information. About. Any. Hotels. Beyond. The. Two. You. Provided: Hotel A and Hotel B, both in Paris with a rating of 4.5.\n",
                  "\n",
                  "Llama3 response:\n",
                  "Hotel A and Hotel B are in Paris.\n",
                  "\n",
                  "Gemma response:\n",
                  "Hotel A and Hotel B are in Paris. \n",
                  "\n"
               ]
            }
         ],
         "source": [
            "chains = {name: prompt_template | model for name, model in models.items()}\n",
            "\n",
            "for name, chain in chains.items():\n",
            "    response = chain.invoke({\n",
            "        \"context\": \"Hotel A and Hotel B are in Paris with rating 4.5\",\n",
            "        \"question\": \"Which hotels are in Paris?\"\n",
            "    })\n",
            "\n",
            "    print(f\"\\n{name} response:\")\n",
            "    print(response.content)\n"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": ".venv",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.14.0"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 5
}